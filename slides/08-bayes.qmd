---
title: 'Bayesian Inference and Linear Regression `r fontawesome::fa("scale-unbalanced")`'
subtitle: "MSSC 6250 Statistical Machine Learning"
author: "Dr. Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University"
# date: "`r format(Sys.time(), '%B %d %Y')`"
# macros: _macros.tex # import a list of TeX/LaTeX definitions
format: 
  revealjs:
    html-math-method:
      method: mathjax
      url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    # include-in-header:
    #     - "macros.tex"
    highlight-style: github
    code-block-bg: true
    self-contained: false
    slide-number: c/t
    incremental: false
    width: 1800
    height: 1000
    margin: 0.05
    logo: "https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg"
    footer: "[mssc6250-s25.github.io/website](https://mssc6250-s25.github.io/website/)"
    theme: ["simple", "styles.scss"]
    echo: false
    multiplex: true
    code-link: true
    fig-cap-location: bottom
    fig-align: center
    transition: none ## fade slide convex concave zoom
    code-line-numbers: false
    title-slide-attributes:
      data-background-color: "#447099"
      # data-background-image: images/paper-texture.jpg
      # data-background-size: cover
      # data-background-color: "#698ED5"
editor: source
execute:
  freeze: true
  echo: false
---


# {visibility="hidden"}


\def\bx{\mathbf{x}}
\def\bg{\mathbf{g}}
\def\bbeta{\boldsymbol \beta}
\def\bX{\mathbf{X}}
\def\by{\mathbf{y}}
\def\bH{\mathbf{H}}
\def\bI{\mathbf{I}}
\def\bS{\mathbf{S}}
\def\T{\text{T}}
\def\cov{\mathrm{Cov}}
\def\cor{\mathrm{Corr}}
\def\var{\mathrm{Var}}
\def\E{\mathrm{E}}
\def\bmu{\boldsymbol \mu}
\def\btheta{\boldsymbol \theta}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\def\Trace{\text{Trace}}



```{r}
#| label: setup
#| include: false
#| eval: true
library(countdown)
library(knitr)
library(gt)
library(gtExtras)
library(ggplot2)
library(ISLR2)
library(genridge)
library(glmnet)
library(gam)
library(splines)
library(tidyverse)
library(bayesrules)
library(rstanarm)
# library(ElemStatLearn)
knitr::opts_chunk$set(
    fig.asp = 0.618,
    fig.align = "center",
    out.width = "100%",
    fig.retina = 10,
    fig.path = "images/08-bayes/",
    message = FALSE,
    global.par = TRUE
)
options(
  htmltools.dir.version = FALSE,
  dplyr.print_min = 6, 
  dplyr.print_max = 6,
  tibble.width = 80,
  width = 80,
  digits = 3
  )
hook_output <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```


```{r}
plot_beta_binomial <- function (alpha, beta, y = NULL, n = NULL, prior = TRUE, likelihood = TRUE, 
          posterior = TRUE) 
{
    if (is.null(y) | is.null(n)) 
        warning("To visualize the posterior,\n            specify data y and n")
    g <- ggplot(data = data.frame(x = c(0, 1)), aes(x)) + labs(x = expression(theta), 
                                                               y = "Density") + scale_fill_manual("", values = c(prior = "#f0e442", 
                                                                                                                 `(scaled) likelihood` = "#0071b2", posterior = "#009e74"), 
                                                                                                  breaks = c("prior", "(scaled) likelihood", "posterior"))
    if (prior == TRUE) {
        g <- g + stat_function(fun = dbeta, args = list(shape1 = alpha, 
                                                        shape2 = beta)) + stat_function(fun = dbeta, args = list(shape1 = alpha, 
                                                                                                                 shape2 = beta), geom = "area", alpha = 0.4, aes(fill = "prior"))
    }
    if (!is.null(y) & !is.null(n)) {
        alpha_post <- alpha + y
        beta_post <- beta + n - y
        y_data <- y
        like_scaled <- function(x) {
            like_fun <- function(x) {
                dbinom(x = y_data, size = n, prob = x)
            }
            scale_c <- integrate(like_fun, lower = 0, upper = 1)[[1]]
            like_fun(x)/scale_c
        }
    }
    if (!is.null(y) & !is.null(n) & (likelihood != FALSE)) {
        g <- g + stat_function(fun = like_scaled) + stat_function(fun = like_scaled, 
                                                                  geom = "area", alpha = 0.4, aes(fill = "(scaled) likelihood"))
    }
    if (!is.null(y) & !is.null(n) & posterior == TRUE) {
        g <- g + stat_function(fun = dbeta, args = list(shape1 = alpha_post, 
                                                        shape2 = beta_post)) + stat_function(fun = dbeta, 
                                                                                             args = list(shape1 = alpha_post, shape2 = beta_post), 
                                                                                             geom = "area", alpha = 0.4, aes(fill = "posterior"))
    }
    g + theme_light()
}

```




# Bayesian Inference*

## Thinking like a Bayesian

1. [When flipping a fair coin, we say that "the probability of flipping Heads is 0.5." How do you interpret this probability?]{.green}

    a. If I flip this coin over and over, roughly 50% will be Heads.
    b. Heads and Tails are equally plausible.
    c. Both a. and b. make sense.
  
  
. . .

2. [An election is coming up and a pollster claims that candidate Yu has a 0.9 probability of winning. How do you interpret this probability?]{.green}

    a. If we observe the election over and over, candidate Yu will win roughly 90% of the time. 
    b. Candidate Yu is much more likely to win than to lose.
    c. The pollster’s calculation is wrong. Candidate Yu will either win or lose, thus their probability of winning can only be 0 or 1.

. . .

- __1.__ a = 1 pt, b = 3 pts, c = 2 pts
- __2.__ a = 1 pt, b = 3 pts, c = 1 pt



## Thinking like a Bayesian

3. [Two claims.]{.green}

    [(1) Ben claims he can predict the coin flip outcome. To test his claim, you flip a fair coin 8 times and he correctly predicts all.]{.green} 
    
    [(2) Emma claims she can distinguish natural and artificial sweeteners. To test her claim, you give her 8 samples and she correctly identifies each.]{.green} 
    
    [In light of these experiments, what do you conclude?]{.green}

    a. You're more confident in Emma's claim than Ben's claim.
    b. The evidence supporting Ben's claim is just as strong as the evidence supporting Emma's claim.

. . .

4. [Suppose that during a doctor’s visit, you tested positive for COVID. If you only get to ask the doctor one question, which would it be?]{.green}

    a. What's the chance that I actually have COVID?
    b. If in fact I don't have COVID, what's the chance that I would've gotten this positive test result?
    
. . .

- __3.__ a = 3 pts, b = 1 pt
- __4.__ a = 3 pts, b = 1 pt


::: notes
Totals from 4–5 indicate that your current thinking is fairly frequentist, whereas totals from 9–12 indicate alignment with the Bayesian philosophy. In between these extremes, totals from 6–8 indicate that you see strengths in both philosophies.
::: 



## Frequentist or Bayesian?

:::: {.columns}

::: {.column width="50%"}

- Totals **4-5**: your thinking is **frequentist**

```{r}
#| out-width: 50%
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/a/aa/Youngronaldfisher2.JPG")
```

:::


::: {.column width="50%"}

- Totals **9-12**: your thinking is **Bayesian**

```{r}
#| out-width: 67%
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif")
```

:::

::::


. . .

- Totals **6-8**: you see strengths in both philosophies




## The Meaning of Probability: **Relative Frequency**

- The *frequentist* interprets probability as the [*long-run* relative frequency of a *repeatable* experiment]{.green}.

. . .

The probability that some outcome of a process will be obtained is defined as 

> the **relative frequency** with which that outcome would be obtained _if the process were repeated **a large number of times** independently under **similar conditions**._

. . .

:::: {.columns}

::: {.column width="50%"}
```{r}
#| label: toss-coin
rel_freq_head <- rep(0, 2)
times <- c(10, 1000)
set.seed(7826)
for (i in 1:2) {
  x <- sample(c("Heads", "Tails"), times[i], replace = TRUE)
  freq_table <- as.matrix(table(x)); colnames(freq_table) <- "Frequency"
  rel_freq_table <- cbind(freq_table, "Relative Frequency" = freq_table[, 1] / times[i])
  rel_freq_table <- rbind(rel_freq_table, Total = apply(rel_freq_table, 2, sum))
  print(rel_freq_table)
  cat("---------------------\n")
  rel_freq_head[i] <- rel_freq_table[1, 2]
}
```
- If we repeat tossing the coin 10 times, the probability of obtaining heads is `r rel_freq_head[1] * 100`%. 
- If 1000 times, the probability is `r rel_freq_head[2] * 100`%.
:::



::: {.column width="50%"}
```{r}
knitr::include_graphics("./images/08-bayes/coin.png")
```
:::
::::

::: notes
source: usplash
:::



## Issues of **Relative Frequency**

- `r emo::ji('confused')` How large of a number is large enough? 

. . .

- `r emo::ji('confused')` Meaning of "under similar conditions"

. . .

- `r emo::ji('confused')` The relative frequency is reliable under identical conditions?

. . .

- `r emo::ji('point_right')`  We only obtain an approximation instead of exact value.

. . .

- `r emo::ji('joy')`  How do you compute the probability that Chicago Cubs wins the World Series next year? 

```{r}
#| out-width: 40%
knitr::include_graphics("https://media.giphy.com/media/EKURBxKKkw0uY/giphy.gif")
```



## The Meaning of Probability: **Relative Plausibility**

- In the *Bayesian* philosophy, a probability measures the [**relative plausibility**]{.green} of an event.

. . .

:::: {.columns}

::: {.column width="50%"}

- For the statement "_candidate A has a 0.9 probability of winning_"
  + A frequentist might say
    i. the conclusion is wrong
    ii. (weirdly) in long-run *hypothetical* repetitions of the election, candidate A would win roughly 90% of the time.
  
  + A Bayesian would say based on analysis the candidate A is 9 times more likely to win than to lose.
:::


::: {.column width="50%"}
:::{.xsmall}
```{r}
#| out-width: 100%
#| fig-cap: "Source: https://twitter.com/nytgraphics/status/796195155158171648/photo/1"
knitr::include_graphics("./images/08-bayes/winning.jpeg")
```
:::
:::
::::



::: notes

- For the statement "_the probability of flipping Heads is 0.5_"
  + A frequentist would conclude that if we flip the coin over and over, roughly 1/2 of these flips will be Heads.
  + A Bayesian would conclude that Heads and Tails are equally likely.

:::





## Your Degree of Uncertainty or Ignorance

::: xsmall
```{r}
#| out-width: 100%
#| fig-link: https://www.gov.uk/government/news/defence-intelligence-communicating-probability
#| fig-cap: "Source: Defence Intelligence – communicating probability"
#| fig-cap-location: margin
knitr::include_graphics("./images/08-bayes/probability_yardstick.jpg")
```
:::

<!-- :::: {.columns} -->

<!-- ::: {.column width="50%"} -->

- I'm gonna flip a coin, and ask you the probability it'll come up heads. You say "50–50".

::: {.fragment}
- I then flip the coin, take a peek, but cover it up, and ask: what's **your** probability it's heads now?
:::

::: {.fragment}
- The event has happened, and no randomness left - just your **ignorance**!
:::


<!-- ::: -->


<!-- ::: {.column width="50%"} -->



<!-- ::: -->

<!-- :::: -->

. . .

David Spiegelhalter (2024). [Why probability probably doesn’t exist (but it is useful to act like it does)](https://www.nature.com/articles/d41586-024-04096-5). **Nature**, 636, p. 560 - 563.


::: notes
it handles both chance and ignorance.

I will argue — whether in a scientific paper, as part of weather forecasts, predicting the outcome of a sports competition or quantifying a health risk — is not an objective property of the world, but a construction based on personal or collective judgements and (often doubtful) assumptions. Furthermore, in most circumstances, it is not even estimating some underlying ‘true’ quantity. Probability, indeed, can only rarely be said to ‘exist’ at all.

To get a handle on probability’s slipperiness, consider how the concept is used in modern weather forecasts. Meteorologists make predictions of temperature, wind speed and quantity of rain, and often also the probability of rain — say 70% for a given time and place. The first three can be compared with their ‘true’ values; you can go out and measure them. But there is no ‘true’ probability to compare the last with the forecaster’s assessment. There is no ‘probability-ometer’. It either rains or it doesn’t.

There is another lesson in here. Even if there is a statistical model for what should happen, this is always based on subjective assumptions

My argument is that any practical use of probability involves subjective judgements. This doesn’t mean that I can put any old numbers on my thoughts — I would be proved a poor probability assessor if I claimed with 99.9% certainty that I can fly off my roof, for example. The objective world comes into play when probabilities, and their underlying assumptions, are tested against reality (see ‘How ignorant am I?’); but that doesn’t mean the probabilities themselves are objective.
:::




## Everybody Changes Their Mind

> How can we live if we don’t change? 
> - Beyoncé. Lyric from “Satellites.”


- Using **data** and **prior beliefs** to update our knowledge (**posterior**), and repeating.


- We continuously update our knowledge about the world as we accumulate lived experiences, or *collect data*.

::: xsmall

```{r}
#| out-width: 55%
#| fig-cap: "Fig 1.1 of https://www.bayesrulesbook.com/. The figures not being sourced come from this book too."
#| fig-cap-location: bottom
knitr::include_graphics("./images/08-bayes/restaurant_diagram.png")
```

:::


::: notes
Everybody changes their mind. You likely even changed your mind in the last minute.
For example, suppose there’s a new Italian restaurant in your town. It has a 5-star online rating and you love Italian food! Thus, prior to ever stepping foot in the restaurant, you anticipate that it will be quite delicious. On your first visit, you collect some edible data: your pasta dish arrives a soggy mess. Weighing the stellar online rating against your own terrible meal (which might have just been a fluke), you update your knowledge: this is a 3-star not 5-star restaurant. Willing to give the restaurant another chance, you make a second trip. On this visit, you’re pleased with your Alfredo and increase the restaurant’s rating to 4 stars. You continue to visit the restaurant, collecting edible data and updating your knowledge each time.
:::



## Bayesian Knowledge-building Process


```{r}
#| out-width: 30%
#| fig-cap-location: bottom

knitr::include_graphics("./images/08-bayes/bayes_diagram.png")
```


::: notes
If you’re an environmental scientist, yours might be an analysis of the human role in climate change. You don’t walk into such an inquiry without context – you carry a degree of incoming or prior information based on previous research and experience. Naturally, it’s in light of this information that you interpret new data, weighing both in developing your updated or posterior information.
:::


## Frequentist Relys on (Limited) Data Only

- In Question 3, in a frequentist analysis, "8 out of 8" is "8 out of 8" no matter if it's in the context of Ben's coins or Emma's sweeteners.
  + *Equally confident* conclusions that Ben can predict coin flips and Emma can distinguish between natural and artificial sweeteners.

```{r}
#| out-width: 30%
#| fig-cap-location: bottom
knitr::include_graphics("./images/08-bayes/freq_diagram.png")
```


. . .

- But do you really believe Ben's claim 100\%? `r emo::ji('thinking')` `r emo::ji('confused')`

. . .


- In fact, we judge their claim before evidence are collected, don't we? `r emo::ji('thinking')`

. . .

- You probably think Ben overstates his ability but Emma's claim sounds relatively reasonable, right?





## The Bayesian Balancing

- Frequentist throws out all prior knowledge in favor of a mere 8 data points.

. . .

- Bayesian analyses *balance* and *weight* our prior experience/knowledge/belief and new data/evidence to judge a claim or make a conclusion.


```{r}
#| out-width: 56%
#| fig-cap-location: bottom
knitr::include_graphics("./images/08-bayes/bayes-balance-1.png")
```

. . .

:::: {.columns}

::: {.column width="80%"}
- [*We are not stubborn!*]{.green} If Ben had correctly predicted the outcome of *1 million* coin flips, the strength of this data would far surpass that of our prior judgement, leading to a posterior conclusion that perhaps Ben is psychic!
:::




::: {.column width="20%"}
```{r}
#| out-width: 60%
knitr::include_graphics("./images/08-bayes/psychic.jpeg")
```
:::
::::



::: notes

Seeing is believing

:::



## Asking Different Questions

:::: {.columns}

::: {.column width="80%"}


In Question 4,

- Bayesians answer (a) *what's the chance that I actually have COVID?*
- Frequentists answer (b) *if in fact I do not have COVID, what's the chance that I would’ve gotten this positive test result?*
:::


::: {.column width="20%"}

```{r}
knitr::include_graphics("./images/08-bayes/covid.jpeg")
```
:::
::::

. . .

+---------------+---------------+----------------------+-------------+
|               | Test Positive | Test Negative        | Total       |
+===============+===============+======================+=============+
| COVID         | 3             | 1                    | 4           |
+---------------+---------------+----------------------+-------------+
| No COVID      | 9             | 87                   |  96         |
+---------------+---------------+----------------------+-------------+
| Total         | 12            | 88                   | 100         |
+---------------+---------------+----------------------+-------------+


- $H_0$: Do not have COVID vs. $H_1$: Have COVID

- A frequestist assesses *the uncertainty of the observed data in light of an assumed hypothesis* $P(Data \mid H_0) = 9/96$

- A Bayesian assesses *the uncertainty of the hypothesis in light of the observed data* $P(H_0 \mid Data) = 9/12$







::: notes
a Bayesian analysis would ask: Given my positive test result, what’s the chance that I actually have the disease? Since only 3 of the 12 people that tested positive have the disease (Table 1.1), there’s only a 25% chance that you have the disease. Thus, when we take into account the disease’s rarity and the relatively high false positive rate, it’s relatively unlikely that you actually have the disease. What a relief.

since disease status isn’t repeatable, the probability you have the disease is either 1 or 0 – you have it or you don’t. To the contrary, medical testing (and data collection in general) is repeatable. You can get tested for the disease over and over and over. Thus, a frequentist analysis would ask: If I don’t actually have the disease, what’s the chance that I would’ve tested positive? Since only 9 of the 96 people without the disease tested positive, there’s a roughly 10% (9/96) chance that you would’ve tested positive even if you didn’t have the disease.
:::




## Fake News

:::: {.columns}

::: {.column width="80%"}

- To do: Predict whether or not if an incoming article is fake.

```{r}
# Load packages
library(bayesrules)
library(tidyverse)
library(janitor)
# Import article data
# data(fake_news)
# glimpse(fake_news[, c("type", "title_has_excl")])
```

<br>

- [**Prior info**:]{.green} 40% of the articles are fake

```{r}
#| eval: false
fake_news |>  
  tabyl(type) |>  
  adorn_totals("row")
```
::::


::: {.column width="20%"}
```{r}
knitr::include_graphics("./images/08-bayes/fake_news.jpeg")
```
:::
::::


. . .

- [**Data come in**:]{.green} Check several fake and real articles, and found `!` is more consistent with fake news (Evidence).

```{r}
# Tabulate exclamation usage and article type
fake_news |>  
  tabyl(title_has_excl, type) |> 
  adorn_totals("row")
```


::: notes
The usage of an `!` might seem odd for a real article. The exclamation point data is more consistent with fake news.
:::




## Bayesian Updating Rule


```{r}
#| out-width: 60%
#| fig-cap-location: bottom
knitr::include_graphics("./images/08-bayes/fake_news_diagram.png")
```

- $F$: *an article is fake*.

- The **prior probability model**

+--------------------------+---------------+----------------------+-------------+
| Event                    | $F$           | $F^c$                | Total       |
+==========================+===============+======================+=============+
| Probability $P(\cdot)$   | 0.4           | 0.6                  | 1           |
+--------------------------+---------------+----------------------+-------------+




## Bayesian Model for Events

```{r}
#| fig-cap-location: bottom
knitr::include_graphics("./images/08-bayes/fake_news_diagram.png")
```

```{r}
fake_news |> 
  tabyl(title_has_excl, type) |> 
  adorn_totals("row")
```

- $D$: *an article title has exclamation mark*.

- Conditional probability: $P(D \mid {\color{blue}{F}}) = 16/60 = 27\%$; $P(D \mid {\color{blue}{F^c}}) = 2/90 = 2\%$.

. . .

- [ **Opposite position**]{.green}: 
    + Know the incoming article used `!` (observed data ${\color{blue}{D}}$)
    + Don't know whether or not the article is fake $F$ (what we want to decide).

. . .

- Compare $P(D \mid F)$ and $P(D \mid F^c)$ to ascertain the relative **likelihoods** of *observed data* ${\color{blue}{D}}$ under different scenarios of the *uncertain* article status.


::: notes
Since exclamation point usage is so much more likely among fake news than real news, this data provides some evidence that the article is fake
To help distinguish this application of conditional probability calculations from that when  
D is uncertain and F is known, we’ll utilize the following likelihood function notation.
:::



## Likelihood Function

::: {.midi}

- **Likelihood function** $L(\cdot\mid {\color{blue}{D}})$:


$$L(F \mid {\color{blue}{D}}) = P({\color{blue}{D}} \mid F) \text{ and } L(F^c \mid {\color{blue}{D}}) = P({\color{blue}{D}} \mid F^c)$$
:::

::: {.fragment .fade-in-then-out}

::: {.midi}
- When ${\color{blue}{F}}$ is known, the *conditional probability* function $P(\cdot \mid {\color{blue}{F}})$ compares the probabilities of an unknown event $D$, $D^c$, occurring with $F$: 
$$P(D \mid {\color{blue}{F}}) \text{  vs. } P(D^c \mid {\color{blue}{F}})$$
:::

:::


::: {.fragment .fade-up}

::: {.midi}

- When ${\color{blue}{D}}$ is known, the *likelihood function* $L(\cdot \mid {\color{blue}{D}}) = P({\color{blue}{D}} \mid \cdot)$ evaluates the *relative compatibility* of data $D$ with $F$ or $F^c$: 
$$L(F \mid {\color{blue}{D}}) \text{  vs. } L(F^c \mid {\color{blue}{D}})$$
:::

:::


. . .


::: {.small}
+-------------------------------+---------------+----------------------+-------------+
| Event                         | $F$           | $F^c$                | Total       |
+===============================+===============+======================+=============+
| Probability $P(\cdot)$        | 0.4           | 0.6                  | 1           |
+-------------------------------+---------------+----------------------+-------------+
| Likelihood  $L(\cdot \mid D)$ | 0.27          | 0.02                 | 0.29        |
+-------------------------------+---------------+----------------------+-------------+
:::

. . .

- [_The likelihood function is not a probability function!_]{.green}







## Bayes' Rule

$$\begin{align*} P(F \mid D) &= \frac{P(F \cap D)}{P(D)}\\ &= \frac{L(F \mid D)P(F)}{P(D)}\end{align*}$$

. . .

$$\text{posterior = } \frac{\text{likelihood} \cdot \text{prior }}{ \text{normalizing constant}} $$

- The normalizing constant $P(D)$ is known as **marginal likelihood** or **evidence**.


:::notes
$$\begin{align*} P(F \mid D) &= \frac{P(F \cap D)}{P(D)}\\ &= \frac{P(D \mid F)P(F)}{P(D)} \\ &= \frac{P(D \mid F)P(F)}{P(D \mid F)P(F) + P(D \mid F^c)P(F^c)}\\ &= \frac{L(F \mid D)P(F)}{L(F \mid D)P(F) + L(F^c \mid D)P(F^c)}\end{align*}$$
:::



## Posterior

- Started with a prior understanding that there's a 40% chance that the incoming article would be fake.

. . .

- Yet upon observing the use of an exclamation point in the title 

::: {.center}

> *“The president has a funny secret!”*

:::

a feature that's more common to fake news.

- Our posterior understanding evolved quite a bit – the chance that the article is fake jumped to 89%.


+-------------------------------------+---------------+----------------------+-------------+
| Event                               | $F$           | $F^c$                | Total       |
+=====================================+===============+======================+=============+
| Prior prob  $P(\cdot)$              | 0.4           | 0.6                  | 1           |
+-------------------------------------+---------------+----------------------+-------------+
| Posterior prob $P(\cdot \mid D)$    | 0.89          | 0.11                 | 1           |
+-------------------------------------+---------------+----------------------+-------------+




## Bayesian Inference for Random Variables

For any random variables parameter $\theta$ and data ${\bf Y} = (Y_1, \dots, Y_n)$, 

- $\pi(\theta)$: the prior pmf/pdf of $\theta$

- $L(\theta \mid y_1,\dots, y_n)$: the likelihood of $\theta$ given observed data $\by = \{y_i \}_{i = 1}^n$. 

- The posterior distribution of $\theta$ given $\by$ is

$$\pi(\theta \mid \by) = \frac{L(\theta \mid \by)\pi(\theta)}{p(\by)}$$ where $$p(\by) = \begin{cases} \int_{\Theta} L(\theta \mid \by)\pi(\theta) ~ d\theta & \text{if } \theta \text{ is continuous }\\ 
\sum_{\theta \in \Theta} L(\theta \mid \by)\pi(\theta) & \text{if } \theta \text{ is discrete }
\end{cases}$$



## Proportionality

$$\pi(\theta \mid \by) = \frac{L(\theta \mid \by)\pi(\theta)}{p(\by)} \propto_{\theta} L(\theta \mid \by)\pi(\theta)$$


$$\text{posterior } \propto \text{ likelihood } \cdot \text{ prior } $$




## Motivation Example

:::: {.columns}

::: {.column width="70%"}

- Michelle has decided to run for governor of Wisconsin.

<!-- - You've conducted 30 different polls throughout the election season. -->

- According to *previous* 30 polls, 
  + Michelle's support is centered round 45%
  + she polled at around 35% in the dreariest days and around 55% in the best days

- With this prior information, we'd like to estimate/update Michelle's support by *conducting a new poll*.

:::


::: {.column width="30%"}

```{r}
knitr::include_graphics("./images/08-bayes/vote.jpeg")
```

:::

::::


Key: Describe prior and data information using probabilistic models.

. . .

- The parameter to be estimated is $\theta$, the Michelle's support, which is between 0 and 1.


## Prior Distribution

- A popular probability distribution for probability is **beta distribution**, $\text{beta}(\alpha, \beta)$, where $\alpha > 0$ and $\beta > 0$ are shape parameters.

$$\pi(\theta \mid \alpha, \beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1-\theta)^{\beta-1}$$

```{r}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/f/f3/Beta_distribution_pdf.svg")
```



## Prior Distribution

- $\theta \sim \text{beta}(\alpha, \beta)$

- In the prior model, $\alpha$ and $\beta$ are **hyperparameters** to be chosen to reflect our prior information.

. . .

> Michelle's support is centered round 45%, and she polled at around 35% in the dreariest days and around 55% in the best days.

- Choose $\alpha$ and $\beta$ so that the *prior mean is about 0.45* and *the range is from 0.35 to 0.55*.


- $\E(\theta) = \frac{\alpha}{\alpha + \beta}$

- $\var(\theta) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$



## Prior Distribution

```{r}
par(mar = c(3, 3, 2, 0), mgp = c(2, 0.6, 0))
x <- seq(0, 1, by = 0.0001)
plot(x, dbeta(x, 45, 55), type = "l", lwd = 3, col = 2, las = 1,
     xlab = expression(theta), ylab = expression(pi(theta)))
title(main = "Prior Distribtuion: beta(45, 55)")
```


## Likelihood

> You plan to conduct a new poll of $n = 50$ Cheeseheads and record $Y$, the number that support Michelle.

::: {.question}
What distribution can be used for modeling likelihood connecting the data $y$ and the parameter we are interested, $\theta$?
:::

. . .

- If voters answer the poll *independently*, and the probability that any polled voter supports Michelle is $\theta$, we could consider 

$$Y \mid \theta \sim \text{binomial}(n=50, \theta)$$

. . .

- The poll result is $y = 30$, the likelihood is

$$L(\theta \mid y = 30) = {50 \choose 30}\theta^{30}(1-\theta)^{20}, \quad \theta \in (0, 1)$$





## Likelihood


```{r}
par(mar = c(3, 3, 2, 0), mgp = c(2, 0.6, 0))
x <- seq(0, 1, by = 0.0001)
y <- choose(50, 30) * x ^ 30 * (1 - x) ^ 20
plot(x, y, type = "l", lwd = 3, col = 4, las = 1,
     xlab = expression(theta), ylab = expression(paste("L(", theta, " | ", y, ")")))
title(main = "Likelihood function")
```




## Bayesian Model

$$\begin{align}Y \mid \theta &\sim \text{binomial}(n=50, \theta)\\ \theta &\sim \text{beta}(45, 55)
\end{align}$$

Goal: Obtain the posterior distribution $\pi(\theta \mid y)$.

. . .

$$
\begin{align} \pi(\theta \mid y) &\propto_{\theta} L(\theta \mid y)\pi(\theta) \\
&= {50 \choose 30}\theta^{30}(1-\theta)^{20} \times \frac{\Gamma(100)}{\Gamma(45)\Gamma(55)}\theta^{44}(1-\theta)^{54}\\
&\propto_{\theta} \theta^{74}(1-\theta)^{74}\\
&= \frac{\Gamma(150)}{\Gamma(75)\Gamma(75)} \theta^{74}(1-\theta)^{74} \\
&= \text{beta}(75, 75)\end{align}
$$

using the fact that $\int_{\mathcal{X}} f(x) dx = 1$ for any pdf $f(x)$.




## Posterior Distribution

```{r}
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)
```




## Take-home Message


:::: {.columns}

::: {.column width="50%"}

[**Bayesian/Probabilistic**]{.green}

- The parameter is *random*
    + The parameter keeps changing.
    + Even the parameter is fixed and constant, the probability distribution associated with it reflects our *ignorance*, *uncertainty*, and *plausibility* of its value, the probability we really want!

:::


::: {.column width="50%"}

[**Frequentist/Classical**]{.green}

- The parameter is *fixed* and *constant*
    + The probability is approximated by relative frequency.
    + The uncertainty is from the *randomness of data*.

:::

::::

# Bayesian Linear Regression*

```{r}
library(bayesrules)
library(tidyverse)
library(rstan)
library(rstanarm)
library(bayesplot)
library(tidybayes)
library(janitor)
library(broom.mixed)
```



## Normal Data Model

In simple linear regression,

$$Y_i \mid \beta_0, \beta_1, \sigma \stackrel{ind}{\sim}  N\left(\mu_i, \sigma^2 \right) \quad \text{with} \quad \mu_i = \beta_0 + \beta_1 X_i$$

This normal data model is our likelihood $L(\btheta = (\beta_0, \beta_1, \sigma) \mid \mathcal{D} = \{\by, \bx \})$, as it evaluates how the data are compatible with different possible values of parameters.

::: {.question}
To be a Bayesian, what do we do next?
:::

. . .

- Assign priors to the unknown parameters, then do the posterior inference using Bayes' rule!

. . .

- Big question is how?



## Prior Models

- There are countless approaches to construct priors for $\beta_0, \beta_1$, and $\sigma$.

. . .

- For simplicity, assume $\beta_0, \beta_1$, and $\sigma$ are [*independent*]{.green}, $\pi(\btheta) = \pi(\beta_0, \beta_1, \sigma) = \pi(\beta_0)\pi(\beta_1)\pi(\sigma)$

. . .

- $\beta_0$ and $\beta_1$ can technically take any values in the real line.

$$\begin{align} \beta_0 \sim N(m_0, s_0^2) \\
 \beta_1 \sim N(m_1, s_1^2) \end{align}$$
 
. . .

- $\sigma$ must be positive.

$$\begin{align} \sigma \sim \text{Exp}(\lambda) \end{align}$$
$\pi(\sigma) = \lambda e^{-\lambda \sigma}$, $\lambda > 0$ and $\E(\sigma) = 1/\lambda$, and $\var(\sigma) = 1/\lambda^2$


::: notes
https://mc-stan.org/rstanarm/articles/priors.html
:::


## Bayesian Simple Linear Regression Model


$$\begin{align} Y_i \mid \beta_0, \beta_1, \sigma &\stackrel{ind}{\sim}  N\left(\mu_i, \sigma^2 \right) \quad \text{with} \quad \mu_i = \beta_0 + \beta_1 X_i \\
\beta_0 &\sim N(m_0, s_0^2) \\
 \beta_1 &\sim N(m_1, s_1^2) \\
\sigma &\sim \text{Exp}(\lambda) \end{align}$$




## Capital Bikeshare [`bayesrules::bikes`](https://cran.r-project.org/web/packages/bayesrules/bayesrules.pdf) Data in *Washington, D.C.*

```{r}
data(bikes)
glimpse(bikes[, c("rides", "temp_feel")])
par(mar = c(4, 4, 0, 0), mgp = c(2.8, 0.6, 0))
plot(bikes$temp_feel, bikes$rides, xlab = "Temparature", ylab = "# of rides", las = 1, col = "grey", pch = 16)
abline(lm(rides ~ temp_feel, data = bikes), col = 2, lwd = 2)
```



## Tuning Prior Models

- [*Prior understanding 1*]{.green}:
  + On an average temperature day, say 65 or 70 degrees, there are typically around 5000 riders, though this average could be somewhere between 3000 and 7000.
  
. . .

- The prior information tells us something about $\beta_0$, but the information has been *centered*. 
  + The **centered intercept**, $\beta_{0c}$, reflects the *typical* ridership at the *typical* temperature.

$\beta_{0c} \sim N(5000, 1000^2)$

```{r}
#| out-width: 40%
par(mar = c(4, 4, 0, 0), mgp = c(2.8, 0.6, 0))
x <- runif(100, 43, 95)
y <- -2000 + 100 * x + rnorm(100, 0, sd = 1250)
plot(x, y, xlim = c(-30, 100), ylim = c(-5000, 8500), las = 1, pch = 16,
     xlab = "Temparature", ylab = "# of rides", cex = 0)
abline(v = mean(x), lty = 2, col = 2, lwd = 2)
abline(h = mean(y), lty = 2, col = 2, lwd = 2)
abline(v = 0, lty = 3, lwd = 0.5)
abline(h = 0, lty = 3, lwd = 0.5)
# abline(lm(y~x))
```






## Tuning Prior Models

- [*Prior understanding 2*]{.green}:
  + For every one degree increase in temperature, ridership typically increases by 100 rides, though this average increase could be as low as 20 or as high as 180.

. . .

$\beta_{1} \sim N(100, 40^2)$

```{r}
#| out-width: 55%
par(mar = c(4, 4, 0, 0), mgp = c(2.8, 0.6, 0))
# x <- runif(100, 43, 95)
# y <- -2000 + 100 * x + rnorm(100, 0, sd = 1250)
plot(x, y, xlim = c(-30, 100), ylim = c(-5000, 8500), las = 1, pch = 16,
     xlab = "Temparature", ylab = "# of rides", cex = 0)
abline(v = mean(x), lty = 2)
abline(h = mean(y), lty = 2)
abline(v = 0, lty = 3, lwd = 0.5)
abline(h = 0, lty = 3, lwd = 0.5)
abline(lm(y~x), col = 2, lwd = 3)
```



  
## Tuning Prior Models

- [*Prior understanding 3*]{.green}:
  + At any given temperature, daily ridership will tend to vary with a moderate standard deviation of 1250 rides.

. . .

$\sigma \sim \text{Exp}(0.0008)$ because $\E(\sigma) = 1/\lambda = 1/0.0008 = 1250$

```{r}
#| out-width: 55%
par(mar = c(4, 4, 0, 0), mgp = c(2.8, 0.6, 0))
# x <- runif(100, 43, 95)
# y <- -2000 + 100 * x + rnorm(100, 0, sd = 1250)
plot(x, y, xlim = c(-30, 100), ylim = c(-5000, 8500), las = 1, pch = 16,
     xlab = "Temparature", ylab = "# of rides", col = 2)
abline(v = mean(x), lty = 2)
abline(h = mean(y), lty = 2)
abline(v = 0, lty = 3, lwd = 0.5)
abline(h = 0, lty = 3, lwd = 0.5)
abline(lm(y~x), col = 1, lwd = 1)
```



## Prior Model Simulation

- 100 prior plausible model lines $\mu_{Y|X} = \beta_0 + \beta_1 X$

```{r}
x <- runif(100, 43, 95)
center_x <- x - mean(x)
beta0 <- rnorm(100, mean = 5000, sd = 1000)
beta1 <- rnorm(100, mean = 100, sd = 40)
sig <- rexp(100, rate = 0.0008)
y_dat <- matrix(0, 100, 100)
lm_lst <- vector("list", 100)
for (i in 1:100) {
    y <- beta0[i] + beta1[i] * center_x + rnorm(100, 0, sd = sig[i])
    y_dat[, i] <- y
    lm_lst[[i]] <- lm(y_dat[, i]~x)
}
par(mar = c(4, 4, 0, 0), mgp = c(2.8, 0.6, 0))
plot(x, y, xlim = c(40, 100), ylim = c(-2000, 14000), las = 1, pch = 16,
     xlab = "Temparature", ylab = "# of rides", cex = 0)
for (i in 1:100) {
    abline(a = beta0[i] - beta1[i]*mean(x), b = beta1[i], col = i,
           lty = i)
}
```




## Posterior Inference 

- Update our prior understanding of the relationship between ridership and temperature using data information provided by likelihood.

- The joint posterior distribution is

$$\pi(\beta_0, \beta_1, \sigma \mid \by) = \frac{L(\beta_0, \beta_1, \sigma \mid \by)\pi(\beta_0, \beta_1, \sigma)}{p(\by)}$$
where 

- $L(\beta_0, \beta_1, \sigma \mid \by) = p(\by \mid \beta_0, \beta_1, \sigma) = \prod_{i=1}^np(y_i \mid \beta_0, \beta_1, \sigma)$

- $\pi(\beta_0, \beta_1, \sigma) = \pi(\beta_0)\pi(\beta_1)\pi(\sigma)$

- $p(\by) = \int \int \int \left[\prod_{i=1}^np(y_i \mid \beta_0, \beta_1, \sigma)\right]\pi(\beta_0)\pi(\beta_1)\pi(\sigma) ~ d\beta_0d\beta_1d\sigma$

- There are lots of ways to generate/approximate the posterior distribution of parameters. One method is **Markov chain Monte Carlo** (MCMC).




## [`rstanarm::stan_glm()`](https://mc-stan.org/rstanarm/)

- `rstanarm` uses [RStan](http://mc-stan.org/rstan/) syntax^[RStan is the R interface to [Stan](https://mc-stan.org/).] to do Bayesian inference for _applied regression models_ (arm).

```{r}
#| cache: true
#| eval: true
#| results: hide
#| echo: true
bike_model <- rstanarm::stan_glm(rides ~ temp_feel, data = bikes,
                                 family = gaussian,
                                 prior_intercept = normal(5000, 1000),
                                 prior = normal(100, 40), 
                                 prior_aux = exponential(0.0008),
                                 chains = 4, iter = 5000*2, seed = 2025)
```

- Generate 4 Monte Carlo chains (`chains = 4`), each having 10000 iterations (`iter = 5000*2`).

- Each iteration draw a posterior sample of the $\beta_0$, $\beta_1$, and $\sigma$.

- After tossing out the first half of Markov chain values from the **warm-up** or **burn-in** phase, `stan_glm()` simulation produces four parallel chains of length 5000 for each model parameter:

$\{ \beta_0^{(1)}, \beta_0^{(2)}, \dots, \beta_0^{(5000)} \}$, 
$\{ \beta_1^{(1)}, \beta_1^{(2)}, \dots, \beta_1^{(5000)} \}$, 
$\{ \sigma^{(1)}, \sigma^{(2)}, \dots, \sigma^{(5000)} \}$





## Convergence Diagnostics

```{r}
#| echo: true
# Trace plots of parallel chains
bayesplot::mcmc_trace(bike_model, size = 0.1)
```


## Convergence Diagnostics

::: xsmall

```{r}
#| fig-cap: "Source: https://blog.stata.com/2016/11/15/introduction-to-bayesian-statistics-part-2-mcmc-and-the-metropolis-hastings-algorithm/"
knitr::include_graphics("https://blog.stata.com/wp-content/uploads/2016/11/animation3.gif")
```

:::



## Convergence Diagnostics

```{r}
#| out-width: 100%
knitr::include_graphics("./images/08-bayes/metropolis_hastings_animation.gif")
```



## Convergence Diagnostics

```{r}
#| echo: true
# Density plots of parallel chains
bayesplot::mcmc_dens_overlay(bike_model)
```



::: notes
- quantifies the number of independent samples it would take to produce an equivalently accurate posterior approximation.
- we observe that these four chains produce nearly indistinguishable posterior approximations. This provides evidence that our simulation is stable and sufficiently long – running the chains for more iterations likely wouldn’t produce drastically different or improved posterior approximations.
:::





## Convergence Diagnostics

```{r}
#| echo: true
# Effective sample size ratio
bayesplot::neff_ratio(bike_model)
# Rhat
bayesplot::rhat(bike_model)
```

- Both effective sample size and R-hat are close to 1, indicating that the chains are *stable*, *mixing quickly*, and behaving much like an *independent* sample.


::: notes
- There’s no magic rule for interpreting this ratio, and it should be utilized alongside other diagnostics such as the trace plot. That said, we might be suspicious of a Markov chain for which the effective sample size ratio is less than 0.1, i.e., the effective sample size is less than 10% of the actual sample size.
- an R-hat ratio greater than 1.05 raises some red flags about the stability of the simulation.
:::


## Convergence Issues

:::: {.columns}

::: {.column width="50%"}

- [*Highly Autocorrelated Chain*]{.green}: Effective size is small, not many independent samples that are representative of the true posterior distribution.
  + Run longer and *thinning* the chain

```{r}
par(mar = c(4, 2, 2, 0), mgp = c(2.8, 0.6, 0))
par(mfrow = c(1, 1))
# good <- rnorm(5000)
auto <- arima.sim(list(order=c(1,0,0), ar=.99), n=5000)
plot(auto, xlab = "Iteration", ylab = "", main = "Highly Autocorrelated Chain",
     las = 1)
```

:::

::: {.column width="50%"}

- [*Slow Convergence*]{.green}: Need wait longer to have the chain reached a stable mixing zone that are representative of the true posterior distribution.
  + Set a longer *burn-in* or *warm-up* period
  
```{r}
par(mar = c(4, 2, 2, 0), mgp = c(2.8, 0.6, 0))
par(mfrow = c(1, 1))
slow <- log(seq(0, 20, length = 5000), base = 10) + rnorm(5000, 0, 0.25)
plot(slow, type = "l", xlab = "Iteration", ylab = "", main = "Slow Convergence", las = 1)
```

:::

::::


## Interpreting the Posterior

```{r}
#| echo: true
# Posterior summary statistics
tidy(bike_model, effects = c("fixed", "aux"),
     conf.int = TRUE, conf.level = 0.80)
```

- The posterior relationship is 

$$-2196 + 82.2 X$$

- The 80% **credible interval** for $\beta_1$ is $(75.7, 88.5)$.

- Given the data, the [*probability that $\beta_1$ is between 75.7 and 88.5 is 80%.*]{.green}, i.e., $P(\beta_1 \in(75.7, 88.5) \mid \by, \bx) = 80\%$.


## Posterior Samples

```{r}
#| echo: true
# Store the 4 chains for each parameter in 1 data frame
bike_model_df <- as.data.frame(bike_model)
nrow(bike_model_df)
head(bike_model_df)
```

How to obtain $P(\beta_1 > 0 \mid \by, \bx)$?

. . .

$P(\beta_1 > 0 \mid \by, \bx) \approx \frac{1}{20000}\sum_{t=1}^{20000} \mathbf{1}\left(\beta_1^{(t)} > 0\right)$

```{r}
#| echo: true
sum(bike_model_df$temp_feel > 0) / nrow(bike_model_df)
```



## Posterior Regression Lines

```{r}
# 100 simulated model lines
bikes |> 
  add_epred_draws(bike_model, ndraws = 100) |> 
  ggplot(aes(x = temp_feel, y = rides)) +
    geom_line(aes(y = .epred, group = .draw), alpha = 0.15) + 
    geom_point(data = bikes, size = 0.5) + theme_light()
```



## Posterior Predictive Draws

For each posterior draw $\{\beta_0^{(t)}, \beta_1^{(t)}, \sigma^{(t)} \}_{t = 1}^{20000}$, we have the **posterior predictive distribution**
$$Y_i^{(t)} \sim N\left(\beta_0^{(t)} + \beta_1^{(t)}X_i, \, (\sigma^{(t)})^2\right)$$

```{r}
# Simulate four sets of data
bikes |> 
  add_predicted_draws(bike_model, ndraws = 4) |> 
  ggplot(aes(x = temp_feel, y = rides)) +
    geom_point(aes(y = .prediction, group = .draw), size = 0.2) + 
    facet_wrap(~ .draw) + theme_light()
```



## Bayesian Interpretation for Ridge and Lasso

- Lasso and Ridge regression can be interpreted as a Bayesian regression model.

- The same data-level likelihood $$Y_i \mid \bbeta, \sigma \stackrel{ind}{\sim}  N\left(\mu_i, \sigma^2 \right) \quad \text{with} \quad \mu_i = \bx_i'\bbeta$$

- We use prior distributions to *regularize* how parameters behave.

. . .

- The two methods can assign the same prior distributions to $\beta_0$ and $\sigma$, but they use *different priors on $\{\beta_j\}_{j = 1}^p$*.^[Remember we usually standardize coefficients before implementing Ridge and Lasso.]
  + [**Lasso**]{.green}: [$\beta_j \stackrel{iid}{\sim} \text{Laplace}\left(0, \tau(\lambda)\right)$](https://en.wikipedia.org/wiki/Laplace_distribution)
  
  + [**Ridge**]{.green}: $\beta_j \stackrel{iid}{\sim} N\left(0, \tau(\lambda)\right)$
 




## Ridge and Lasso Priors

:::: columns

::: column
[**Lasso**]{.green}

:::{style="font-size: 0.8em;"}
$$\beta_j \stackrel{iid}{\sim} \text{Laplace}\left(0, \tau(\lambda)\right)$$

Lasso solution is the **posterior mode** of $\bbeta$

$$\bbeta^{(l)} = \argmax_{\bbeta} \,\,\, \pi(\bbeta \mid \by, \bx)$$
:::

```{r}
par(mar = c(3, 3, 0, 0), mgp = c(2, 0.6, 0))
x <- seq(-3, 3, length = 1000)
lap_dist <- function(x, mu = 0, b) {
    1/(2*b) * exp(- abs(x - mu)/b)
}
plot(x, lap_dist(x, b = sqrt(1/2)), 
     xlab = expression(beta[j]), ylim = c(0, 0.7),
     ylab = expression(paste(pi, "(", beta[j], ")")), type = "l", 
     col = 2, lwd = 3, las = 1)
abline(v = 0, lty = 2, lwd = 0.4)
```

:::

::: column
[**Ridge**]{.green}

:::{style="font-size: 0.8em;"}
$$\beta_j \stackrel{iid}{\sim} N\left(0, \tau(\lambda)\right)$$

Ridge solution is the **posterior mode/mean** of $\bbeta$

$$\bbeta^{(r)} = \argmax_{\bbeta} \,\, \, \pi(\bbeta \mid \by, \bx)$$
:::

```{r}
par(mar = c(3, 3, 0, 0), mgp = c(2, 0.6, 0))
x <- seq(-3, 3, length = 1000)
plot(x, dnorm(x), xlab = expression(beta[j]), ylim = c(0, 0.7),
     ylab = expression(paste(pi, "(", beta[j], ")")), type = "l", 
     col = 2, lwd = 3, las = 1)
abline(v = 0, lty = 2, lwd = 0.4)
```

:::

::::


## Resources

- [Bayes Rules! An Introduction to Applied Bayesian Modeling](https://www.bayesrulesbook.com/)

- [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/)

- [A Student’s Guide to Bayesian Statistics](https://uk.sagepub.com/en-gb/eur/book/student%E2%80%99s-guide-bayesian-statistics)

- [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)



<!-- ## Bayes Factor -->

<!-- ## Posterior Predictive Distribution -->

<!-- ## Sensitivity Analysis -->
