{
  "hash": "3c817934436d8d41f2221d7af68eb1f9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"07- Splines and Generalized Addive Models Code Demo\"\nauthor: 'Dr. Cheng-Han Yu'\nformat: \n  html:\n    toc: true\n    code-link: true\n    code-fold: show\n    code-summary: \"Show/Hide\"\n    code-tools: true\n---\n\n## R implementation\n\n::: {.cell}\n\n```{.r .cell-code}\nbirthrates <- read.csv(\"../data/birthrates.csv\")\n```\n:::\n\n### Polynomial regression\n\n::: {.cell}\n\n```{.r .cell-code}\nlmfit3 <- lm(Birthrate ~ poly(Year-mean(Year), degree = 3), data = birthrates)\nplot(birthrates, pch = 19, col = 4, main = \"degree = 3\")\nlines(birthrates$Year, lmfit3$fitted.values, lty = 1, col = 2, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n<!-- ### Linear splines -->\n\n::: {.cell}\n\n:::\n\n\n### Cubic Splines\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\n```\n:::\n\n\nFor linear splines, change `degree = 3` to `degree = 1`.\n\n::: {.cell}\n\n```{.r .cell-code}\ncub_sp <- lm(Birthrate ~ splines::bs(Year, degree = 3, knots = c(1936, 1960, 1978)), \n             data = birthrates)\nplot(birthrates, pch = 19, col = 4, main = \"Cubic spline (k = 3) with 3 knots\")\nlines(birthrates$Year, cub_sp$fitted.values, lty = 1, col = 2, lwd = 3)\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n### Smoothing Splines\n::: {.cell}\n\n```{.r .cell-code}\nfit <- smooth.spline(birthrates$Year, birthrates$Birthrate, df = 15)\nplot(birthrates$Year, birthrates$Birthrate, pch = 19, \n     xlab = \"Year\", ylab = \"BirthRates\", col = 4)\nlines(seq(1917, 2003), predict(fit, seq(1917, 2003))$y, col = 2, lty = 1, lwd = 3)\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n### GAM\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gam)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: foreach\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoaded gam 1.22-4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nWage <- read.csv(\"../data/Wage.csv\")\nWage$education <- as.factor(Wage$education)\ngam.m3 <- gam(wage ~ s(year, df = 4) + s(age , df = 5) + education, data = Wage)\npar(mfrow = c(1, 3), mar = c(4, 4, 2, 0))\nplot.Gam(gam.m3, se = TRUE, col = 4, lwd = 2, las = 1)\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## Python implementation\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbirthrates = pd.read_csv(\"../data/birthrates.csv\")\n```\n:::\n\n### Polynomial regression\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nbirthrates['Year_centered'] = birthrates['Year'] - birthrates['Year'].mean()\n\n# Polynomial regression with degree = 3\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(birthrates[['Year_centered']])\n\npolyfit3 = LinearRegression().fit(X_poly, birthrates['Birthrate'])\n\nplt.scatter(birthrates['Year'], birthrates['Birthrate'], color='blue')\nplt.plot(birthrates['Year'], polyfit3.predict(X_poly), color='red',\n         linewidth=2)\nplt.title(\"Cubic Polynomial Regression (Degree = 3)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Birthrate\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n<!-- ### Linear splines -->\n\n<!-- ```{python} -->\n<!-- knots = [1936, 1960, 1978] -->\n<!-- # Generate cubic spline basis functions with specified knots -->\n<!-- spline_basis = dmatrix( -->\n<!--     \"bs(Year, degree=1, knots=knots, include_intercept=True)\",  -->\n<!--     {\"Year\": birthrates[\"Year\"]},  -->\n<!--     return_type=\"dataframe\" -->\n<!-- ) -->\n\n<!-- # Fit the cubic spline model -->\n<!-- model = sm.OLS(birthrates[\"Birthrate\"], spline_basis).fit() -->\n\n<!-- # Predict fitted values -->\n<!-- birthrates[\"Fitted\"] = model.fittedvalues -->\n\n<!-- # Plot the data and the fitted spline -->\n<!-- plt.scatter(birthrates[\"Year\"], birthrates[\"Birthrate\"], color=\"blue\", s=50) -->\n<!-- plt.plot(birthrates[\"Year\"], birthrates[\"Fitted\"], color=\"red\", linewidth=3) -->\n<!-- plt.title(\"Linear Spline (k=1) with Specified Knots\") -->\n<!-- plt.xlabel(\"Year\") -->\n<!-- plt.ylabel(\"Birthrate\") -->\n<!-- plt.show() -->\n<!-- ``` -->\n\n\n\n<!-- Pay attention to parameter `t` in the function [`make_lsq_spline()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.make_lsq_spline.html). -->\n\n\n<!-- ```{python} -->\n<!-- from scipy.interpolate import make_lsq_spline -->\n<!-- ``` -->\n\n<!-- ```{python} -->\n<!-- knots = [1936, 1960, 1978] -->\n<!-- k=1 -->\n<!-- # Extend the knots for the boundaries -->\n<!-- augmented_knots = [birthrates[\"Year\"].min()] * (k+1) + knots + [birthrates[\"Year\"].max()] * (k+1) -->\n\n<!-- linear_spline = make_lsq_spline( -->\n<!--     x=birthrates[\"Year\"].values,  # x values -->\n<!--     y=birthrates[\"Birthrate\"].values,  # y values -->\n<!--     t=augmented_knots,  # Knots -->\n<!--     k=k  # Degree of the spline -->\n<!-- ) -->\n\n<!-- # Generate fitted values -->\n<!-- fitted_values = linear_spline(birthrates[\"Year\"]) -->\n\n<!-- # Plot the original data -->\n<!-- plt.scatter(birthrates[\"Year\"], birthrates[\"Birthrate\"], color='blue', s=50, -->\n<!--             label=\"Data\") -->\n<!-- plt.plot(birthrates[\"Year\"], fitted_values, color='red', linewidth=3, -->\n<!--          label=\"Fitted Spline\") -->\n<!-- plt.title(\"Linear Spline (d = 1) with 3 Knots\") -->\n<!-- plt.xlabel(\"Year\") -->\n<!-- plt.ylabel(\"Birthrate\") -->\n<!-- plt.legend() -->\n<!-- plt.show() -->\n<!-- ``` -->\n\n\n\n\n### Cubic Splines\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom patsy import dmatrix\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\nFor linear splines, change `degree=3` to `degree=1`.\n\nNOTE:\n\n- Can't find prediction or extrapolation for cubic splines.\n\n- Use [`patsy.cr()`](https://patsy.readthedocs.io/en/latest/API-reference.html#patsy.cr) to fit natural cubic splines.\n\n::: {.cell}\n\n```{.python .cell-code}\nknots = [1936, 1960, 1978]\n# https://patsy.readthedocs.io/en/latest/API-reference.html\n# Generate cubic spline basis functions with specified knots\nspline_basis = dmatrix(\n    \"bs(Year, degree=3, knots=knots, include_intercept=True)\", \n    {\"Year\": birthrates[\"Year\"]}, \n    return_type=\"dataframe\"\n)\n# Fit the cubic spline model\n# import statsmodels.api as sm\n# model = sm.OLS(birthrates[\"Birthrate\"], spline_basis).fit()\n# birthrates[\"Fitted\"] = model.fittedvalues\ncub_sp = LinearRegression().fit(spline_basis, birthrates[\"Birthrate\"])\n\n# Plot the data and the fitted spline\nplt.scatter(birthrates[\"Year\"], birthrates[\"Birthrate\"], color=\"blue\")\nplt.plot(birthrates[\"Year\"], cub_sp.predict(spline_basis), color=\"red\",\n         linewidth=2)\nplt.title(\"Cubic Spline (d=3) with 3 Knots\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Birthrate\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-14-3.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# https://patsy.readthedocs.io/en/latest/API-reference.html\n# Generate cubic spline basis functions with specified knots\nspline_basis = dmatrix(\n    \"bs(Year, degree=3, df=7, include_intercept=True)\", \n    {\"Year\": birthrates[\"Year\"]}, \n    return_type=\"dataframe\"\n)\n# Fit the cubic spline model\n# import statsmodels.api as sm\n# model = sm.OLS(birthrates[\"Birthrate\"], spline_basis).fit()\n# birthrates[\"Fitted\"] = model.fittedvalues\ncub_sp = LinearRegression().fit(spline_basis, birthrates[\"Birthrate\"])\n\n# Plot the data and the fitted spline\nplt.scatter(birthrates[\"Year\"], birthrates[\"Birthrate\"], color=\"blue\")\nplt.plot(birthrates[\"Year\"], cub_sp.predict(spline_basis), color=\"red\",\n         linewidth=2)\nplt.title(\"Cubic Spline (df=6)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Birthrate\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-15-5.png){width=672}\n:::\n:::\n\n\n### Smoothing Splines\n\nWe use [`scipy.interpolate.make_smoothing_spline`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.make_smoothing_spline.html).\n\n- Python has no functions for smoothing splines that can directly specify the degrees of freedom. Please let me know if you find one.\n\n- To have similar smoothing results, R and Python would use quite a different size of penalty term $\\lambda$, as well as the degrees of freedom and smoothing factor.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.interpolate import make_smoothing_spline\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nx = birthrates[\"Year\"].values\ny = birthrates[\"Birthrate\"].values\nspline = make_smoothing_spline(x, y, lam=20)\n# Predict for the range of years\nx_pred = np.linspace(1917, 2003, 500)\ny_pred = spline(x_pred)\n# Plot the original data\nplt.figure(figsize=(10, 6))\nplt.scatter(x, y, color='blue', label='Data', s=50)\nplt.plot(x_pred, y_pred, color='red', linewidth=3, label='Smoothing Spline')\nplt.title(\"Smoothing Spline\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Birthrate\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-17-7.png){width=960}\n:::\n:::\n\n\n\nTo use a smoothing factor, use [`splrep` (`make_splrep`)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splrep.html#scipy.interpolate.splrep) and [`BSpline`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.BSpline.html#scipy.interpolat.BSpline)\n\nThe smoothing factor is set unresonably high to 4500. Please let me know if you figure out why.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.interpolate import splrep, BSpline\n```\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nx = birthrates[\"Year\"].values\ny = birthrates[\"Birthrate\"].values\n\n# Fit the smoothing spline with a smoothing factor\nsmoothing_factor = 4500 # Adjust this for the desired smoothness\ntck = splrep(x, y, s=smoothing_factor)\n\n# Predict for a range of years\nx_pred = np.linspace(1917, 2003, 500)\ny_pred = BSpline(*tck)(x_pred)\n\n# Plot the original data\nplt.figure(figsize=(10, 6))\nplt.scatter(x, y, color='blue', label='Data', s=50)\n\n# Plot the fitted smoothing spline\nplt.plot(x_pred, y_pred, color='red', linewidth=3, label='Smoothing Spline')\n\n# Add labels and title\nplt.title(\"Smoothing Spline with splrep\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Birthrate\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-19-9.png){width=960}\n:::\n:::\n\n### GAM\n\n<https://kirenz.github.io/regression/docs/gam.html>\n\n<https://gist.github.com/josef-pkt/453de603b019143e831fbdd4dfb6aa30>\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.gam.api import BSplines\nfrom statsmodels.gam.api import GLMGam\nfrom statsmodels.tools.eval_measures import mse, rmse\nimport statsmodels.api as sm\nimport patsy\n```\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nWage = pd.read_csv(\"../data/Wage.csv\")\nWage['education'] = pd.Categorical(Wage['education'], categories=['1. < HS Grad', '2. HS Grad', '3. Some College', '4. College Grad', '5. Advanced Degree'], ordered=True)\n\n# penalization weights are taken from mgcv to match up its results\n# sp = np.array([0.830689464223685, 425.361212061649])\n# s_scale = np.array([2.443955e-06, 0.007945455])\nx_spline = Wage[['year', 'age']].values\nexog = patsy.dmatrix('education', data=Wage)\n\n# TODO: set `include_intercept=True` automatically if constraints='center'\nbs = BSplines(x_spline, df=[4, 5], degree=[3, 3], variable_names=['year', 'age'], \n              constraints='center', include_intercept=True)\n# alpha = 1 / s_scale * sp / 2\ngam_bs = GLMGam(Wage['wage'], exog=exog, smoother=bs)\nres = gam_bs.fit()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nres.plot_partial(0, cpr=False, include_constant=False, ax=axes[0])\naxes[0].set_title(\"Year\")\nres.plot_partial(1, cpr=False, include_constant=False, ax=axes[1])\naxes[1].set_title(\"Age\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-22-11.png){width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(res.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                   wage   No. Observations:                 3000\nModel:                         GLMGam   Df Residuals:                     2988\nModel Family:                Gaussian   Df Model:                        11.00\nLink Function:               Identity   Scale:                          1238.8\nMethod:                         PIRLS   Log-Likelihood:                -14934.\nDate:                Mon, 10 Feb 2025   Deviance:                   3.7014e+06\nTime:                        21:43:15   Pearson chi2:                 3.70e+06\nNo. Iterations:                     3   Pseudo R-squ. (CS):             0.3358\nCovariance Type:            nonrobust                                         \n===================================================================================================\n                                      coef    std err          z      P>|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------------\nIntercept                          85.6860      2.156     39.745      0.000      81.461      89.911\neducation[T.2. HS Grad]            10.7413      2.431      4.418      0.000       5.977      15.506\neducation[T.3. Some College]       23.2067      2.563      9.056      0.000      18.184      28.229\neducation[T.4. College Grad]       37.8704      2.547     14.871      0.000      32.879      42.862\neducation[T.5. Advanced Degree]    62.4355      2.764     22.591      0.000      57.019      67.852\nyear_s0                             3.3874      4.257      0.796      0.426      -4.957      11.732\nyear_s1                             1.8170      4.220      0.431      0.667      -6.454      10.088\nyear_s2                             4.4943      1.754      2.563      0.010       1.057       7.931\nage_s0                             10.1360      5.932      1.709      0.087      -1.490      21.762\nage_s1                             47.6380      5.326      8.945      0.000      37.200      58.076\nage_s2                              6.7739      7.296      0.928      0.353      -7.526      21.074\nage_s3                            -10.0472     10.672     -0.941      0.346     -30.963      10.869\n===================================================================================================\n```\n\n\n:::\n:::\n\n\nOne option is to use [`pygam`](https://pygam.readthedocs.io/en/latest/index.html) package.\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom pygam import LinearGAM, s, f\nfrom pygam.datasets import wage\n```\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nX, y = wage(return_X_y=True)\n\n## model\ngam = LinearGAM(s(0) + s(1) + f(2)).fit(X, y)\n\nfor i, term in enumerate(gam.terms):\n    if term.isintercept:\n        continue\n\n    XX = gam.generate_X_grid(term=i)\n    pdep, confi = gam.partial_dependence(term=i, X=XX, width=0.95)\n\n    plt.figure()\n    plt.plot(XX[:, term.feature], pdep)\n    plt.plot(XX[:, term.feature], confi, c='r', ls='--')\n    plt.title(repr(term))\n    plt.show()\n```\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-25-13.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-25-14.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](07-splines-code_files/figure-html/unnamed-chunk-25-15.png){width=672}\n:::\n\n```{.python .cell-code}\ngam.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinearGAM                                                                                                 \n=============================================== ==========================================================\nDistribution:                        NormalDist Effective DoF:                                     25.1911\nLink Function:                     IdentityLink Log Likelihood:                                -24118.6847\nNumber of Samples:                         3000 AIC:                                            48289.7516\n                                                AICc:                                           48290.2307\n                                                GCV:                                             1255.6902\n                                                Scale:                                           1236.7251\n                                                Pseudo R-Squared:                                   0.2955\n==========================================================================================================\nFeature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n================================= ==================== ============ ============ ============ ============\ns(0)                              [0.6]                20           7.1          5.95e-03     **          \ns(1)                              [0.6]                20           14.1         1.11e-16     ***         \nf(2)                              [0.6]                5            4.0          1.11e-16     ***         \nintercept                                              1            0.0          1.11e-16     ***         \n==========================================================================================================\nSignificance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nWARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n         which can cause p-values to appear significant when they are not.\n\nWARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n         are typically lower than they should be, meaning that the tests reject the null too readily.\n<string>:3: UserWarning: KNOWN BUG: p-values computed in this summary are likely much smaller than they should be. \n \nPlease do not make inferences based on these values! \n\nCollaborate on a solution, and stay up to date at: \ngithub.com/dswah/pyGAM/issues/163 \n```\n\n\n:::\n:::\n\n",
    "supporting": [
      "07-splines-code_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}