{
  "hash": "a3328e7708e9ab93529b3d98db7b33b1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Bayesian Inference and Linear Regression `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 640 512\" style=\"height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M522.1 62.4c16.8-5.6 25.8-23.7 20.2-40.5S518.6-3.9 501.9 1.6l-113 37.7C375 15.8 349.3 0 320 0c-44.2 0-80 35.8-80 80c0 3 .2 5.9 .5 8.8L117.9 129.6c-16.8 5.6-25.8 23.7-20.2 40.5s23.7 25.8 40.5 20.2l135.5-45.2c4.5 3.2 9.3 5.9 14.4 8.2V480c0 17.7 14.3 32 32 32H512c17.7 0 32-14.3 32-32s-14.3-32-32-32H352V153.3c21-9.2 37.2-27 44.2-49l125.9-42zM439.6 288L512 163.8 584.4 288H439.6zM512 384c62.9 0 115.2-34 126-78.9c2.6-11-1-22.3-6.7-32.1L536.1 109.8c-5-8.6-14.2-13.8-24.1-13.8s-19.1 5.3-24.1 13.8L392.7 273.1c-5.7 9.8-9.3 21.1-6.7 32.1C396.8 350 449.1 384 512 384zM129.2 291.8L201.6 416H56.7l72.4-124.2zM3.2 433.1C14 478 66.3 512 129.2 512s115.2-34 126-78.9c2.6-11-1-22.3-6.7-32.1L153.2 237.8c-5-8.6-14.2-13.8-24.1-13.8s-19.1 5.3-24.1 13.8L9.9 401.1c-5.7 9.8-9.3 21.1-6.7 32.1z\"/></svg>`{=html}'\nsubtitle: \"MSSC 6250 Statistical Machine Learning\"\nauthor: \"Dr. Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University\"\n# date: \"February 15 2025\"\n# macros: _macros.tex # import a list of TeX/LaTeX definitions\nformat: \n  revealjs:\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n    # include-in-header:\n    #     - \"macros.tex\"\n    highlight-style: github\n    code-block-bg: true\n    self-contained: false\n    slide-number: c/t\n    incremental: false\n    width: 1800\n    height: 1000\n    margin: 0.05\n    logo: \"https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg\"\n    footer: \"[mssc6250-s25.github.io/website](https://mssc6250-s25.github.io/website/)\"\n    theme: [\"simple\", \"styles.scss\"]\n    echo: false\n    multiplex: true\n    code-link: true\n    fig-cap-location: bottom\n    fig-align: center\n    transition: none ## fade slide convex concave zoom\n    code-line-numbers: false\n    title-slide-attributes:\n      data-background-color: \"#447099\"\n      # data-background-image: images/paper-texture.jpg\n      # data-background-size: cover\n      # data-background-color: \"#698ED5\"\neditor: source\nexecute:\n  freeze: true\n  echo: false\n---\n\n\n# {visibility=\"hidden\"}\n\n\n\\def\\bx{\\mathbf{x}}\n\\def\\bg{\\mathbf{g}}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\bX{\\mathbf{X}}\n\\def\\by{\\mathbf{y}}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\T{\\text{T}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\def\\E{\\mathrm{E}}\n\\def\\bmu{\\boldsymbol \\mu}\n\\def\\btheta{\\boldsymbol \\theta}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\DeclareMathOperator*{\\argmax}{arg\\,max}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n# Bayesian Inference*\n\n## Thinking like a Bayesian\n\n1. [When flipping a fair coin, we say that \"the probability of flipping Heads is 0.5.\" How do you interpret this probability?]{.green}\n\n    a. If I flip this coin over and over, roughly 50% will be Heads.\n    b. Heads and Tails are equally plausible.\n    c. Both a. and b. make sense.\n  \n  \n. . .\n\n2. [An election is coming up and a pollster claims that candidate Yu has a 0.9 probability of winning. How do you interpret this probability?]{.green}\n\n    a. If we observe the election over and over, candidate Yu will win roughly 90% of the time. \n    b. Candidate Yu is much more likely to win than to lose.\n    c. The pollster’s calculation is wrong. Candidate Yu will either win or lose, thus their probability of winning can only be 0 or 1.\n\n. . .\n\n- __1.__ a = 1 pt, b = 3 pts, c = 2 pts\n- __2.__ a = 1 pt, b = 3 pts, c = 1 pt\n\n\n\n## Thinking like a Bayesian\n\n3. [Two claims.]{.green}\n\n    [(1) Ben claims he can predict the coin flip outcome. To test his claim, you flip a fair coin 8 times and he correctly predicts all.]{.green} \n    \n    [(2) Emma claims she can distinguish natural and artificial sweeteners. To test her claim, you give her 8 samples and she correctly identifies each.]{.green} \n    \n    [In light of these experiments, what do you conclude?]{.green}\n\n    a. You're more confident in Emma's claim than Ben's claim.\n    b. The evidence supporting Ben's claim is just as strong as the evidence supporting Emma's claim.\n\n. . .\n\n4. [Suppose that during a doctor’s visit, you tested positive for COVID. If you only get to ask the doctor one question, which would it be?]{.green}\n\n    a. What's the chance that I actually have COVID?\n    b. If in fact I don't have COVID, what's the chance that I would've gotten this positive test result?\n    \n. . .\n\n- __3.__ a = 3 pts, b = 1 pt\n- __4.__ a = 3 pts, b = 1 pt\n\n\n::: notes\nTotals from 4–5 indicate that your current thinking is fairly frequentist, whereas totals from 9–12 indicate alignment with the Bayesian philosophy. In between these extremes, totals from 6–8 indicate that you see strengths in both philosophies.\n::: \n\n\n\n## Frequentist or Bayesian?\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- Totals **4-5**: your thinking is **frequentist**\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/a/aa/Youngronaldfisher2.JPG){fig-align='center' width=50%}\n:::\n:::\n\n:::\n\n\n::: {.column width=\"50%\"}\n\n- Totals **9-12**: your thinking is **Bayesian**\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif){fig-align='center' width=67%}\n:::\n:::\n\n:::\n\n::::\n\n\n. . .\n\n- Totals **6-8**: you see strengths in both philosophies\n\n\n\n\n## The Meaning of Probability: **Relative Frequency**\n\n- The *frequentist* interprets probability as the [*long-run* relative frequency of a *repeatable* experiment]{.green}.\n\n. . .\n\nThe probability that some outcome of a process will be obtained is defined as \n\n> the **relative frequency** with which that outcome would be obtained _if the process were repeated **a large number of times** independently under **similar conditions**._\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n      Frequency Relative Frequency\nHeads         4                0.4\nTails         6                0.6\nTotal        10                1.0\n---------------------\n      Frequency Relative Frequency\nHeads       512              0.512\nTails       488              0.488\nTotal      1000              1.000\n---------------------\n```\n\n\n:::\n:::\n- If we repeat tossing the coin 10 times, the probability of obtaining heads is 40%. \n- If 1000 times, the probability is 51.2%.\n:::\n\n\n\n::: {.column width=\"50%\"}\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/coin.png){fig-align='center' width=100%}\n:::\n:::\n:::\n::::\n\n::: notes\nsource: usplash\n:::\n\n\n\n## Issues of **Relative Frequency**\n\n- 😕 How large of a number is large enough? \n\n. . .\n\n- 😕 Meaning of \"under similar conditions\"\n\n. . .\n\n- 😕 The relative frequency is reliable under identical conditions?\n\n. . .\n\n- 👉  We only obtain an approximation instead of exact value.\n\n. . .\n\n- 😂  How do you compute the probability that Chicago Cubs wins the World Series next year? \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://media.giphy.com/media/EKURBxKKkw0uY/giphy.gif){fig-align='center' width=40%}\n:::\n:::\n\n\n\n## The Meaning of Probability: **Relative Plausibility**\n\n- In the *Bayesian* philosophy, a probability measures the [**relative plausibility**]{.green} of an event.\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- For the statement \"_candidate A has a 0.9 probability of winning_\"\n  + A frequentist might say\n    i. the conclusion is wrong\n    ii. (weirdly) in long-run *hypothetical* repetitions of the election, candidate A would win roughly 90% of the time.\n  \n  + A Bayesian would say based on analysis the candidate A is 9 times more likely to win than to lose.\n:::\n\n\n::: {.column width=\"50%\"}\n:::{.xsmall}\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Source: https://twitter.com/nytgraphics/status/796195155158171648/photo/1](./images/08-bayes/winning.jpeg){fig-align='center' width=100%}\n:::\n:::\n:::\n:::\n::::\n\n\n\n::: notes\n\n- For the statement \"_the probability of flipping Heads is 0.5_\"\n  + A frequentist would conclude that if we flip the coin over and over, roughly 1/2 of these flips will be Heads.\n  + A Bayesian would conclude that Heads and Tails are equally likely.\n\n:::\n\n\n\n\n\n## Your Degree of Uncertainty or Ignorance\n\n::: xsmall\n::: {.cell .fig-cap-location-margin layout-align=\"center\"}\n::: {.cell-output-display}\n[![Source: Defence Intelligence – communicating probability](./images/08-bayes/probability_yardstick.jpg){fig-align='center' width=100%}](https://www.gov.uk/government/news/defence-intelligence-communicating-probability)\n:::\n:::\n:::\n\n<!-- :::: {.columns} -->\n\n<!-- ::: {.column width=\"50%\"} -->\n\n- I'm gonna flip a coin, and ask you the probability it'll come up heads. You say \"50–50\".\n\n::: {.fragment}\n- I then flip the coin, take a peek, but cover it up, and ask: what's **your** probability it's heads now?\n:::\n\n::: {.fragment}\n- The event has happened, and no randomness left - just your **ignorance**!\n:::\n\n\n<!-- ::: -->\n\n\n<!-- ::: {.column width=\"50%\"} -->\n\n\n\n<!-- ::: -->\n\n<!-- :::: -->\n\n. . .\n\nDavid Spiegelhalter (2024). [Why probability probably doesn’t exist (but it is useful to act like it does)](https://www.nature.com/articles/d41586-024-04096-5). **Nature**, 636, p. 560 - 563.\n\n\n::: notes\nit handles both chance and ignorance.\n\nI will argue — whether in a scientific paper, as part of weather forecasts, predicting the outcome of a sports competition or quantifying a health risk — is not an objective property of the world, but a construction based on personal or collective judgements and (often doubtful) assumptions. Furthermore, in most circumstances, it is not even estimating some underlying ‘true’ quantity. Probability, indeed, can only rarely be said to ‘exist’ at all.\n\nTo get a handle on probability’s slipperiness, consider how the concept is used in modern weather forecasts. Meteorologists make predictions of temperature, wind speed and quantity of rain, and often also the probability of rain — say 70% for a given time and place. The first three can be compared with their ‘true’ values; you can go out and measure them. But there is no ‘true’ probability to compare the last with the forecaster’s assessment. There is no ‘probability-ometer’. It either rains or it doesn’t.\n\nThere is another lesson in here. Even if there is a statistical model for what should happen, this is always based on subjective assumptions\n\nMy argument is that any practical use of probability involves subjective judgements. This doesn’t mean that I can put any old numbers on my thoughts — I would be proved a poor probability assessor if I claimed with 99.9% certainty that I can fly off my roof, for example. The objective world comes into play when probabilities, and their underlying assumptions, are tested against reality (see ‘How ignorant am I?’); but that doesn’t mean the probabilities themselves are objective.\n:::\n\n\n\n\n## Everybody Changes Their Mind\n\n> How can we live if we don’t change? \n> - Beyoncé. Lyric from “Satellites.”\n\n\n- Using **data** and **prior beliefs** to update our knowledge (**posterior**), and repeating.\n\n\n- We continuously update our knowledge about the world as we accumulate lived experiences, or *collect data*.\n\n::: xsmall\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![Fig 1.1 of https://www.bayesrulesbook.com/. The figures not being sourced come from this book too.](./images/08-bayes/restaurant_diagram.png){fig-align='center' width=55%}\n:::\n:::\n\n:::\n\n\n::: notes\nEverybody changes their mind. You likely even changed your mind in the last minute.\nFor example, suppose there’s a new Italian restaurant in your town. It has a 5-star online rating and you love Italian food! Thus, prior to ever stepping foot in the restaurant, you anticipate that it will be quite delicious. On your first visit, you collect some edible data: your pasta dish arrives a soggy mess. Weighing the stellar online rating against your own terrible meal (which might have just been a fluke), you update your knowledge: this is a 3-star not 5-star restaurant. Willing to give the restaurant another chance, you make a second trip. On this visit, you’re pleased with your Alfredo and increase the restaurant’s rating to 4 stars. You continue to visit the restaurant, collecting edible data and updating your knowledge each time.\n:::\n\n\n\n## Bayesian Knowledge-building Process\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/bayes_diagram.png){fig-align='center' width=30%}\n:::\n:::\n\n\n::: notes\nIf you’re an environmental scientist, yours might be an analysis of the human role in climate change. You don’t walk into such an inquiry without context – you carry a degree of incoming or prior information based on previous research and experience. Naturally, it’s in light of this information that you interpret new data, weighing both in developing your updated or posterior information.\n:::\n\n\n## Frequentist Relys on (Limited) Data Only\n\n- In Question 3, in a frequentist analysis, \"8 out of 8\" is \"8 out of 8\" no matter if it's in the context of Ben's coins or Emma's sweeteners.\n  + *Equally confident* conclusions that Ben can predict coin flips and Emma can distinguish between natural and artificial sweeteners.\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/freq_diagram.png){fig-align='center' width=30%}\n:::\n:::\n\n\n. . .\n\n- But do you really believe Ben's claim 100\\%? 🤔 😕\n\n. . .\n\n\n- In fact, we judge their claim before evidence are collected, don't we? 🤔\n\n. . .\n\n- You probably think Ben overstates his ability but Emma's claim sounds relatively reasonable, right?\n\n\n\n\n\n## The Bayesian Balancing\n\n- Frequentist throws out all prior knowledge in favor of a mere 8 data points.\n\n. . .\n\n- Bayesian analyses *balance* and *weight* our prior experience/knowledge/belief and new data/evidence to judge a claim or make a conclusion.\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/bayes-balance-1.png){fig-align='center' width=56%}\n:::\n:::\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"80%\"}\n- [*We are not stubborn!*]{.green} If Ben had correctly predicted the outcome of *1 million* coin flips, the strength of this data would far surpass that of our prior judgement, leading to a posterior conclusion that perhaps Ben is psychic!\n:::\n\n\n\n\n::: {.column width=\"20%\"}\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/psychic.jpeg){fig-align='center' width=60%}\n:::\n:::\n:::\n::::\n\n\n\n::: notes\n\nSeeing is believing\n\n:::\n\n\n\n## Asking Different Questions\n\n:::: {.columns}\n\n::: {.column width=\"80%\"}\n\n\nIn Question 4,\n\n- Bayesians answer (a) *what's the chance that I actually have COVID?*\n- Frequentists answer (b) *if in fact I do not have COVID, what's the chance that I would’ve gotten this positive test result?*\n:::\n\n\n::: {.column width=\"20%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/covid.jpeg){fig-align='center' width=100%}\n:::\n:::\n:::\n::::\n\n. . .\n\n+---------------+---------------+----------------------+-------------+\n|               | Test Positive | Test Negative        | Total       |\n+===============+===============+======================+=============+\n| COVID         | 3             | 1                    | 4           |\n+---------------+---------------+----------------------+-------------+\n| No COVID      | 9             | 87                   |  96         |\n+---------------+---------------+----------------------+-------------+\n| Total         | 12            | 88                   | 100         |\n+---------------+---------------+----------------------+-------------+\n\n\n- $H_0$: Do not have COVID vs. $H_1$: Have COVID\n\n- A frequestist assesses *the uncertainty of the observed data in light of an assumed hypothesis* $P(Data \\mid H_0) = 9/96$\n\n- A Bayesian assesses *the uncertainty of the hypothesis in light of the observed data* $P(H_0 \\mid Data) = 9/12$\n\n\n\n\n\n\n\n::: notes\na Bayesian analysis would ask: Given my positive test result, what’s the chance that I actually have the disease? Since only 3 of the 12 people that tested positive have the disease (Table 1.1), there’s only a 25% chance that you have the disease. Thus, when we take into account the disease’s rarity and the relatively high false positive rate, it’s relatively unlikely that you actually have the disease. What a relief.\n\nsince disease status isn’t repeatable, the probability you have the disease is either 1 or 0 – you have it or you don’t. To the contrary, medical testing (and data collection in general) is repeatable. You can get tested for the disease over and over and over. Thus, a frequentist analysis would ask: If I don’t actually have the disease, what’s the chance that I would’ve tested positive? Since only 9 of the 96 people without the disease tested positive, there’s a roughly 10% (9/96) chance that you would’ve tested positive even if you didn’t have the disease.\n:::\n\n\n\n\n## Fake News\n\n:::: {.columns}\n\n::: {.column width=\"80%\"}\n\n- To do: Predict whether or not if an incoming article is fake.\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n<br>\n\n- [**Prior info**:]{.green} 40% of the articles are fake\n\n::: {.cell layout-align=\"center\"}\n\n:::\n::::\n\n\n::: {.column width=\"20%\"}\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/fake_news.jpeg){fig-align='center' width=100%}\n:::\n:::\n:::\n::::\n\n\n. . .\n\n- [**Data come in**:]{.green} Check several fake and real articles, and found `!` is more consistent with fake news (Evidence).\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n title_has_excl fake real\n          FALSE   44   88\n           TRUE   16    2\n          Total   60   90\n```\n\n\n:::\n:::\n\n\n::: notes\nThe usage of an `!` might seem odd for a real article. The exclamation point data is more consistent with fake news.\n:::\n\n\n\n\n## Bayesian Updating Rule\n\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/fake_news_diagram.png){fig-align='center' width=60%}\n:::\n:::\n\n- $F$: *an article is fake*.\n\n- The **prior probability model**\n\n+--------------------------+---------------+----------------------+-------------+\n| Event                    | $F$           | $F^c$                | Total       |\n+==========================+===============+======================+=============+\n| Probability $P(\\cdot)$   | 0.4           | 0.6                  | 1           |\n+--------------------------+---------------+----------------------+-------------+\n\n\n\n\n## Bayesian Model for Events\n\n::: {.cell .fig-cap-location-bottom layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/fake_news_diagram.png){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n title_has_excl fake real\n          FALSE   44   88\n           TRUE   16    2\n          Total   60   90\n```\n\n\n:::\n:::\n\n- $D$: *an article title has exclamation mark*.\n\n- Conditional probability: $P(D \\mid {\\color{blue}{F}}) = 16/60 = 27\\%$; $P(D \\mid {\\color{blue}{F^c}}) = 2/90 = 2\\%$.\n\n. . .\n\n- [ **Opposite position**]{.green}: \n    + Know the incoming article used `!` (observed data ${\\color{blue}{D}}$)\n    + Don't know whether or not the article is fake $F$ (what we want to decide).\n\n. . .\n\n- Compare $P(D \\mid F)$ and $P(D \\mid F^c)$ to ascertain the relative **likelihoods** of *observed data* ${\\color{blue}{D}}$ under different scenarios of the *uncertain* article status.\n\n\n::: notes\nSince exclamation point usage is so much more likely among fake news than real news, this data provides some evidence that the article is fake\nTo help distinguish this application of conditional probability calculations from that when  \nD is uncertain and F is known, we’ll utilize the following likelihood function notation.\n:::\n\n\n\n## Likelihood Function\n\n::: {.midi}\n\n- **Likelihood function** $L(\\cdot\\mid {\\color{blue}{D}})$:\n\n\n$$L(F \\mid {\\color{blue}{D}}) = P({\\color{blue}{D}} \\mid F) \\text{ and } L(F^c \\mid {\\color{blue}{D}}) = P({\\color{blue}{D}} \\mid F^c)$$\n:::\n\n::: {.fragment .fade-in-then-out}\n\n::: {.midi}\n- When ${\\color{blue}{F}}$ is known, the *conditional probability* function $P(\\cdot \\mid {\\color{blue}{F}})$ compares the probabilities of an unknown event $D$, $D^c$, occurring with $F$: \n$$P(D \\mid {\\color{blue}{F}}) \\text{  vs. } P(D^c \\mid {\\color{blue}{F}})$$\n:::\n\n:::\n\n\n::: {.fragment .fade-up}\n\n::: {.midi}\n\n- When ${\\color{blue}{D}}$ is known, the *likelihood function* $L(\\cdot \\mid {\\color{blue}{D}}) = P({\\color{blue}{D}} \\mid \\cdot)$ evaluates the *relative compatibility* of data $D$ with $F$ or $F^c$: \n$$L(F \\mid {\\color{blue}{D}}) \\text{  vs. } L(F^c \\mid {\\color{blue}{D}})$$\n:::\n\n:::\n\n\n. . .\n\n\n::: {.small}\n+-------------------------------+---------------+----------------------+-------------+\n| Event                         | $F$           | $F^c$                | Total       |\n+===============================+===============+======================+=============+\n| Probability $P(\\cdot)$        | 0.4           | 0.6                  | 1           |\n+-------------------------------+---------------+----------------------+-------------+\n| Likelihood  $L(\\cdot \\mid D)$ | 0.27          | 0.02                 | 0.29        |\n+-------------------------------+---------------+----------------------+-------------+\n:::\n\n. . .\n\n- [_The likelihood function is not a probability function!_]{.green}\n\n\n\n\n\n\n\n## Bayes' Rule\n\n$$\\begin{align*} P(F \\mid D) &= \\frac{P(F \\cap D)}{P(D)}\\\\ &= \\frac{L(F \\mid D)P(F)}{P(D)}\\end{align*}$$\n\n. . .\n\n$$\\text{posterior = } \\frac{\\text{likelihood} \\cdot \\text{prior }}{ \\text{normalizing constant}} $$\n\n- The normalizing constant $P(D)$ is known as **marginal likelihood** or **evidence**.\n\n\n:::notes\n$$\\begin{align*} P(F \\mid D) &= \\frac{P(F \\cap D)}{P(D)}\\\\ &= \\frac{P(D \\mid F)P(F)}{P(D)} \\\\ &= \\frac{P(D \\mid F)P(F)}{P(D \\mid F)P(F) + P(D \\mid F^c)P(F^c)}\\\\ &= \\frac{L(F \\mid D)P(F)}{L(F \\mid D)P(F) + L(F^c \\mid D)P(F^c)}\\end{align*}$$\n:::\n\n\n\n## Posterior\n\n- Started with a prior understanding that there's a 40% chance that the incoming article would be fake.\n\n. . .\n\n- Yet upon observing the use of an exclamation point in the title \n\n::: {.center}\n\n> *“The president has a funny secret!”*\n\n:::\n\na feature that's more common to fake news.\n\n- Our posterior understanding evolved quite a bit – the chance that the article is fake jumped to 89%.\n\n\n+-------------------------------------+---------------+----------------------+-------------+\n| Event                               | $F$           | $F^c$                | Total       |\n+=====================================+===============+======================+=============+\n| Prior prob  $P(\\cdot)$              | 0.4           | 0.6                  | 1           |\n+-------------------------------------+---------------+----------------------+-------------+\n| Posterior prob $P(\\cdot \\mid D)$    | 0.89          | 0.11                 | 1           |\n+-------------------------------------+---------------+----------------------+-------------+\n\n\n\n\n## Bayesian Inference for Random Variables\n\nFor any random variables parameter $\\theta$ and data ${\\bf Y} = (Y_1, \\dots, Y_n)$, \n\n- $\\pi(\\theta)$: the prior pmf/pdf of $\\theta$\n\n- $L(\\theta \\mid y_1,\\dots, y_n)$: the likelihood of $\\theta$ given observed data $\\by = \\{y_i \\}_{i = 1}^n$. \n\n- The posterior distribution of $\\theta$ given $\\by$ is\n\n$$\\pi(\\theta \\mid \\by) = \\frac{L(\\theta \\mid \\by)\\pi(\\theta)}{p(\\by)}$$ where $$p(\\by) = \\begin{cases} \\int_{\\Theta} L(\\theta \\mid \\by)\\pi(\\theta) ~ d\\theta & \\text{if } \\theta \\text{ is continuous }\\\\ \n\\sum_{\\theta \\in \\Theta} L(\\theta \\mid \\by)\\pi(\\theta) & \\text{if } \\theta \\text{ is discrete }\n\\end{cases}$$\n\n\n\n## Proportionality\n\n$$\\pi(\\theta \\mid \\by) = \\frac{L(\\theta \\mid \\by)\\pi(\\theta)}{p(\\by)} \\propto_{\\theta} L(\\theta \\mid \\by)\\pi(\\theta)$$\n\n\n$$\\text{posterior } \\propto \\text{ likelihood } \\cdot \\text{ prior } $$\n\n\n\n\n## Motivation Example\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\n- Michelle has decided to run for governor of Wisconsin.\n\n<!-- - You've conducted 30 different polls throughout the election season. -->\n\n- According to *previous* 30 polls, \n  + Michelle's support is centered round 45%\n  + she polled at around 35% in the dreariest days and around 55% in the best days\n\n- With this prior information, we'd like to estimate/update Michelle's support by *conducting a new poll*.\n\n:::\n\n\n::: {.column width=\"30%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/vote.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::::\n\n\nKey: Describe prior and data information using probabilistic models.\n\n. . .\n\n- The parameter to be estimated is $\\theta$, the Michelle's support, which is between 0 and 1.\n\n\n## Prior Distribution\n\n- A popular probability distribution for probability is **beta distribution**, $\\text{beta}(\\alpha, \\beta)$, where $\\alpha > 0$ and $\\beta > 0$ are shape parameters.\n\n$$\\pi(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha - 1}(1-\\theta)^{\\beta-1}$$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/f/f3/Beta_distribution_pdf.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Prior Distribution\n\n- $\\theta \\sim \\text{beta}(\\alpha, \\beta)$\n\n- In the prior model, $\\alpha$ and $\\beta$ are **hyperparameters** to be chosen to reflect our prior information.\n\n. . .\n\n> Michelle's support is centered round 45%, and she polled at around 35% in the dreariest days and around 55% in the best days.\n\n- Choose $\\alpha$ and $\\beta$ so that the *prior mean is about 0.45* and *the range is from 0.35 to 0.55*.\n\n\n- $\\E(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}$\n\n- $\\var(\\theta) = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$\n\n\n\n## Prior Distribution\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-25-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Likelihood\n\n> You plan to conduct a new poll of $n = 50$ Cheeseheads and record $Y$, the number that support Michelle.\n\n::: {.question}\nWhat distribution can be used for modeling likelihood connecting the data $y$ and the parameter we are interested, $\\theta$?\n:::\n\n. . .\n\n- If voters answer the poll *independently*, and the probability that any polled voter supports Michelle is $\\theta$, we could consider \n\n$$Y \\mid \\theta \\sim \\text{binomial}(n=50, \\theta)$$\n\n. . .\n\n- The poll result is $y = 30$, the likelihood is\n\n$$L(\\theta \\mid y = 30) = {50 \\choose 30}\\theta^{30}(1-\\theta)^{20}, \\quad \\theta \\in (0, 1)$$\n\n\n\n\n\n## Likelihood\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-26-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Bayesian Model\n\n$$\\begin{align}Y \\mid \\theta &\\sim \\text{binomial}(n=50, \\theta)\\\\ \\theta &\\sim \\text{beta}(45, 55)\n\\end{align}$$\n\nGoal: Obtain the posterior distribution $\\pi(\\theta \\mid y)$.\n\n. . .\n\n$$\n\\begin{align} \\pi(\\theta \\mid y) &\\propto_{\\theta} L(\\theta \\mid y)\\pi(\\theta) \\\\\n&= {50 \\choose 30}\\theta^{30}(1-\\theta)^{20} \\times \\frac{\\Gamma(100)}{\\Gamma(45)\\Gamma(55)}\\theta^{44}(1-\\theta)^{54}\\\\\n&\\propto_{\\theta} \\theta^{74}(1-\\theta)^{74}\\\\\n&= \\frac{\\Gamma(150)}{\\Gamma(75)\\Gamma(75)} \\theta^{74}(1-\\theta)^{74} \\\\\n&= \\text{beta}(75, 75)\\end{align}\n$$\n\nusing the fact that $\\int_{\\mathcal{X}} f(x) dx = 1$ for any pdf $f(x)$.\n\n\n\n\n## Posterior Distribution\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-27-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Take-home Message\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n[**Bayesian/Probabilistic**]{.green}\n\n- The parameter is *random*\n    + The parameter keeps changing.\n    + Even the parameter is fixed and constant, the probability distribution associated with it reflects our *ignorance*, *uncertainty*, and *plausibility* of its value, the probability we really want!\n\n:::\n\n\n::: {.column width=\"50%\"}\n\n[**Frequentist/Classical**]{.green}\n\n- The parameter is *fixed* and *constant*\n    + The probability is approximated by relative frequency.\n    + The uncertainty is from the *randomness of data*.\n\n:::\n\n::::\n\n# Bayesian Linear Regression*\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n## Normal Data Model\n\nIn simple linear regression,\n\n$$Y_i \\mid \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim}  N\\left(\\mu_i, \\sigma^2 \\right) \\quad \\text{with} \\quad \\mu_i = \\beta_0 + \\beta_1 X_i$$\n\nThis normal data model is our likelihood $L(\\btheta = (\\beta_0, \\beta_1, \\sigma) \\mid \\mathcal{D} = \\{\\by, \\bx \\})$, as it evaluates how the data are compatible with different possible values of parameters.\n\n::: {.question}\nTo be a Bayesian, what do we do next?\n:::\n\n. . .\n\n- Assign priors to the unknown parameters, then do the posterior inference using Bayes' rule!\n\n. . .\n\n- Big question is how?\n\n\n\n## Prior Models\n\n- There are countless approaches to construct priors for $\\beta_0, \\beta_1$, and $\\sigma$.\n\n. . .\n\n- For simplicity, assume $\\beta_0, \\beta_1$, and $\\sigma$ are [*independent*]{.green}, $\\pi(\\btheta) = \\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0)\\pi(\\beta_1)\\pi(\\sigma)$\n\n. . .\n\n- $\\beta_0$ and $\\beta_1$ can technically take any values in the real line.\n\n$$\\begin{align} \\beta_0 \\sim N(m_0, s_0^2) \\\\\n \\beta_1 \\sim N(m_1, s_1^2) \\end{align}$$\n \n. . .\n\n- $\\sigma$ must be positive.\n\n$$\\begin{align} \\sigma \\sim \\text{Exp}(\\lambda) \\end{align}$$\n$\\pi(\\sigma) = \\lambda e^{-\\lambda \\sigma}$, $\\lambda > 0$ and $\\E(\\sigma) = 1/\\lambda$, and $\\var(\\sigma) = 1/\\lambda^2$\n\n\n::: notes\nhttps://mc-stan.org/rstanarm/articles/priors.html\n:::\n\n\n## Bayesian Simple Linear Regression Model\n\n\n$$\\begin{align} Y_i \\mid \\beta_0, \\beta_1, \\sigma &\\stackrel{ind}{\\sim}  N\\left(\\mu_i, \\sigma^2 \\right) \\quad \\text{with} \\quad \\mu_i = \\beta_0 + \\beta_1 X_i \\\\\n\\beta_0 &\\sim N(m_0, s_0^2) \\\\\n \\beta_1 &\\sim N(m_1, s_1^2) \\\\\n\\sigma &\\sim \\text{Exp}(\\lambda) \\end{align}$$\n\n\n\n\n## Capital Bikeshare [`bayesrules::bikes`](https://cran.r-project.org/web/packages/bayesrules/bayesrules.pdf) Data in *Washington, D.C.*\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 500\nColumns: 2\n$ rides     <int> 654, 1229, 1454, 1518, 1362, 891, 1280, 1220, 1137, 1368, 13…\n$ temp_feel <dbl> 64.7, 49.0, 51.1, 52.6, 50.8, 46.6, 45.6, 49.2, 46.4, 45.6, …\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-29-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Tuning Prior Models\n\n- [*Prior understanding 1*]{.green}:\n  + On an average temperature day, say 65 or 70 degrees, there are typically around 5000 riders, though this average could be somewhere between 3000 and 7000.\n  \n. . .\n\n- The prior information tells us something about $\\beta_0$, but the information has been *centered*. \n  + The **centered intercept**, $\\beta_{0c}$, reflects the *typical* ridership at the *typical* temperature.\n\n$\\beta_{0c} \\sim N(5000, 1000^2)$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-30-1.png){fig-align='center' width=40%}\n:::\n:::\n\n\n\n\n\n\n## Tuning Prior Models\n\n- [*Prior understanding 2*]{.green}:\n  + For every one degree increase in temperature, ridership typically increases by 100 rides, though this average increase could be as low as 20 or as high as 180.\n\n. . .\n\n$\\beta_{1} \\sim N(100, 40^2)$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-31-1.png){fig-align='center' width=55%}\n:::\n:::\n\n\n\n  \n## Tuning Prior Models\n\n- [*Prior understanding 3*]{.green}:\n  + At any given temperature, daily ridership will tend to vary with a moderate standard deviation of 1250 rides.\n\n. . .\n\n$\\sigma \\sim \\text{Exp}(0.0008)$ because $\\E(\\sigma) = 1/\\lambda = 1/0.0008 = 1250$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-32-1.png){fig-align='center' width=55%}\n:::\n:::\n\n\n\n## Prior Model Simulation\n\n- 100 prior plausible model lines $\\mu_{Y|X} = \\beta_0 + \\beta_1 X$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-33-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Posterior Inference \n\n- Update our prior understanding of the relationship between ridership and temperature using data information provided by likelihood.\n\n- The joint posterior distribution is\n\n$$\\pi(\\beta_0, \\beta_1, \\sigma \\mid \\by) = \\frac{L(\\beta_0, \\beta_1, \\sigma \\mid \\by)\\pi(\\beta_0, \\beta_1, \\sigma)}{p(\\by)}$$\nwhere \n\n- $L(\\beta_0, \\beta_1, \\sigma \\mid \\by) = p(\\by \\mid \\beta_0, \\beta_1, \\sigma) = \\prod_{i=1}^np(y_i \\mid \\beta_0, \\beta_1, \\sigma)$\n\n- $\\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0)\\pi(\\beta_1)\\pi(\\sigma)$\n\n- $p(\\by) = \\int \\int \\int \\left[\\prod_{i=1}^np(y_i \\mid \\beta_0, \\beta_1, \\sigma)\\right]\\pi(\\beta_0)\\pi(\\beta_1)\\pi(\\sigma) ~ d\\beta_0d\\beta_1d\\sigma$\n\n- There are lots of ways to generate/approximate the posterior distribution of parameters. One method is **Markov chain Monte Carlo** (MCMC).\n\n\n\n\n## [`rstanarm::stan_glm()`](https://mc-stan.org/rstanarm/)\n\n- `rstanarm` uses [RStan](http://mc-stan.org/rstan/) syntax^[RStan is the R interface to [Stan](https://mc-stan.org/).] to do Bayesian inference for _applied regression models_ (arm).\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbike_model <- rstanarm::stan_glm(rides ~ temp_feel, data = bikes,\n                                 family = gaussian,\n                                 prior_intercept = normal(5000, 1000),\n                                 prior = normal(100, 40), \n                                 prior_aux = exponential(0.0008),\n                                 chains = 4, iter = 5000*2, seed = 2025)\n```\n:::\n\n- Generate 4 Monte Carlo chains (`chains = 4`), each having 10000 iterations (`iter = 5000*2`).\n\n- Each iteration draw a posterior sample of the $\\beta_0$, $\\beta_1$, and $\\sigma$.\n\n- After tossing out the first half of Markov chain values from the **warm-up** or **burn-in** phase, `stan_glm()` simulation produces four parallel chains of length 5000 for each model parameter:\n\n$\\{ \\beta_0^{(1)}, \\beta_0^{(2)}, \\dots, \\beta_0^{(5000)} \\}$, \n$\\{ \\beta_1^{(1)}, \\beta_1^{(2)}, \\dots, \\beta_1^{(5000)} \\}$, \n$\\{ \\sigma^{(1)}, \\sigma^{(2)}, \\dots, \\sigma^{(5000)} \\}$\n\n\n\n\n\n## Convergence Diagnostics\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Trace plots of parallel chains\nbayesplot::mcmc_trace(bike_model, size = 0.1)\n```\n\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-35-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Convergence Diagnostics\n\n::: xsmall\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Source: https://blog.stata.com/2016/11/15/introduction-to-bayesian-statistics-part-2-mcmc-and-the-metropolis-hastings-algorithm/](https://blog.stata.com/wp-content/uploads/2016/11/animation3.gif){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n\n\n## Convergence Diagnostics\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-bayes/metropolis_hastings_animation.gif){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Convergence Diagnostics\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Density plots of parallel chains\nbayesplot::mcmc_dens_overlay(bike_model)\n```\n\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-38-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n::: notes\n- quantifies the number of independent samples it would take to produce an equivalently accurate posterior approximation.\n- we observe that these four chains produce nearly indistinguishable posterior approximations. This provides evidence that our simulation is stable and sufficiently long – running the chains for more iterations likely wouldn’t produce drastically different or improved posterior approximations.\n:::\n\n\n\n\n\n## Convergence Diagnostics\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Effective sample size ratio\nbayesplot::neff_ratio(bike_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)   temp_feel       sigma \n      0.995       0.992       0.950 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Rhat\nbayesplot::rhat(bike_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)   temp_feel       sigma \n          1           1           1 \n```\n\n\n:::\n:::\n\n- Both effective sample size and R-hat are close to 1, indicating that the chains are *stable*, *mixing quickly*, and behaving much like an *independent* sample.\n\n\n::: notes\n- There’s no magic rule for interpreting this ratio, and it should be utilized alongside other diagnostics such as the trace plot. That said, we might be suspicious of a Markov chain for which the effective sample size ratio is less than 0.1, i.e., the effective sample size is less than 10% of the actual sample size.\n- an R-hat ratio greater than 1.05 raises some red flags about the stability of the simulation.\n:::\n\n\n## Convergence Issues\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- [*Highly Autocorrelated Chain*]{.green}: Effective size is small, not many independent samples that are representative of the true posterior distribution.\n  + Run longer and *thinning* the chain\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-40-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n- [*Slow Convergence*]{.green}: Need wait longer to have the chain reached a stable mixing zone that are representative of the true posterior distribution.\n  + Set a longer *burn-in* or *warm-up* period\n  \n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-41-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::::\n\n\n## Interpreting the Posterior\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Posterior summary statistics\ntidy(bike_model, effects = c(\"fixed\", \"aux\"),\n     conf.int = TRUE, conf.level = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term        estimate std.error conf.low conf.high\n  <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)  -2191.     355.    -2653.    -1735. \n2 temp_feel       82.1      5.07     75.7      88.7\n3 sigma         1282.      41.1    1231.     1336. \n4 mean_PPD      3487.      80.3    3385.     3590. \n```\n\n\n:::\n:::\n\n- The posterior relationship is \n\n$$-2196 + 82.2 X$$\n\n- The 80% **credible interval** for $\\beta_1$ is $(75.7, 88.5)$.\n\n- Given the data, the [*probability that $\\beta_1$ is between 75.7 and 88.5 is 80%.*]{.green}, i.e., $P(\\beta_1 \\in(75.7, 88.5) \\mid \\by, \\bx) = 80\\%$.\n\n\n## Posterior Samples\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Store the 4 chains for each parameter in 1 data frame\nbike_model_df <- as.data.frame(bike_model)\nnrow(bike_model_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20000\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(bike_model_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) temp_feel sigma\n1       -2318      83.0  1304\n2       -2107      81.9  1261\n3       -2460      85.9  1246\n4       -2419      84.7  1394\n5       -2067      79.5  1202\n6       -1806      75.6  1224\n```\n\n\n:::\n:::\n\nHow to obtain $P(\\beta_1 > 0 \\mid \\by, \\bx)$?\n\n. . .\n\n$P(\\beta_1 > 0 \\mid \\by, \\bx) \\approx \\frac{1}{20000}\\sum_{t=1}^{20000} \\mathbf{1}\\left(\\beta_1^{(t)} > 0\\right)$\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(bike_model_df$temp_feel > 0) / nrow(bike_model_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n\n## Posterior Regression Lines\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-45-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Posterior Predictive Draws\n\nFor each posterior draw $\\{\\beta_0^{(t)}, \\beta_1^{(t)}, \\sigma^{(t)} \\}_{t = 1}^{20000}$, we have the **posterior predictive distribution**\n$$Y_i^{(t)} \\sim N\\left(\\beta_0^{(t)} + \\beta_1^{(t)}X_i, \\, (\\sigma^{(t)})^2\\right)$$\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-46-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Bayesian Interpretation for Ridge and Lasso\n\n- Lasso and Ridge regression can be interpreted as a Bayesian regression model.\n\n- The same data-level likelihood $$Y_i \\mid \\bbeta, \\sigma \\stackrel{ind}{\\sim}  N\\left(\\mu_i, \\sigma^2 \\right) \\quad \\text{with} \\quad \\mu_i = \\bx_i'\\bbeta$$\n\n- We use prior distributions to *regularize* how parameters behave.\n\n. . .\n\n- The two methods can assign the same prior distributions to $\\beta_0$ and $\\sigma$, but they use *different priors on $\\{\\beta_j\\}_{j = 1}^p$*.^[Remember we usually standardize coefficients before implementing Ridge and Lasso.]\n  + [**Lasso**]{.green}: [$\\beta_j \\stackrel{iid}{\\sim} \\text{Laplace}\\left(0, \\tau(\\lambda)\\right)$](https://en.wikipedia.org/wiki/Laplace_distribution)\n  \n  + [**Ridge**]{.green}: $\\beta_j \\stackrel{iid}{\\sim} N\\left(0, \\tau(\\lambda)\\right)$\n \n\n\n\n\n## Ridge and Lasso Priors\n\n:::: columns\n\n::: column\n[**Lasso**]{.green}\n\n:::{style=\"font-size: 0.8em;\"}\n$$\\beta_j \\stackrel{iid}{\\sim} \\text{Laplace}\\left(0, \\tau(\\lambda)\\right)$$\n\nLasso solution is the **posterior mode** of $\\bbeta$\n\n$$\\bbeta^{(l)} = \\argmax_{\\bbeta} \\,\\,\\, \\pi(\\bbeta \\mid \\by, \\bx)$$\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-47-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: column\n[**Ridge**]{.green}\n\n:::{style=\"font-size: 0.8em;\"}\n$$\\beta_j \\stackrel{iid}{\\sim} N\\left(0, \\tau(\\lambda)\\right)$$\n\nRidge solution is the **posterior mode/mean** of $\\bbeta$\n\n$$\\bbeta^{(r)} = \\argmax_{\\bbeta} \\,\\, \\, \\pi(\\bbeta \\mid \\by, \\bx)$$\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/08-bayes/unnamed-chunk-48-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::::\n\n\n## Resources\n\n- [Bayes Rules! An Introduction to Applied Bayesian Modeling](https://www.bayesrulesbook.com/)\n\n- [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/)\n\n- [A Student’s Guide to Bayesian Statistics](https://uk.sagepub.com/en-gb/eur/book/student%E2%80%99s-guide-bayesian-statistics)\n\n- [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)\n\n\n\n<!-- ## Bayes Factor -->\n\n<!-- ## Posterior Predictive Distribution -->\n\n<!-- ## Sensitivity Analysis -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}